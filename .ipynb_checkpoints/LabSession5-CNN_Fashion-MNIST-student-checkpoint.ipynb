{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "",
  "signature": "sha256:f69e675530ac22f69bbb8396eb64db26df244730f9aa4daeb8efbd58a8f05a69"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ELU 502 Deep learning -- Lab session 5\n",
      "Pierre-Henri Conze, Fran\u00e7ois Rousseau, Ronan Fablet - session: 1h20 (17th april)+3h (20th april)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Objectives: perform classification on Fashion-MNIST dataset using multiple layer perceptrons, convolutional neural networks, data augmentation and transfer learning to obtain the best classification results as possible!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, download and read the Fashion-MNIST data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import keras\n",
      "from keras.datasets import fashion_mnist\n",
      "\n",
      "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
        "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 1 - Data management and visualization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1) Fashion-MNIST is a dataset consisting of a training set of A examples and a test set of B examples. Each example is a CxC grayscale image, associated with a label from D classes. What are the values for A, B, C and D?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to do\n",
      "A=len(x_train)\n",
      "B=len(x_test)\n",
      "C=x_train.shape[1]\n",
      "D=len(set(y_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each training/test sample is assigned to one of the following labels: \n",
      "0\tT-shirt\n",
      "1\tTrouser\n",
      "2\tPullover\n",
      "3\tDress\n",
      "4\tCoat\n",
      "5\tSandal\n",
      "6\tShirt\n",
      "7\tSneaker\n",
      "8\tBag\n",
      "9\tAnkle boot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_classes = 10\n",
      "class_names = ['tshirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'boot']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2) Visualize one example per class among the training dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "plt.figure()\n",
      "for i in range(num_classes):\n",
      "    plt.subplot(2, 5, i + 1)\n",
      "    plt.axis('off')\n",
      "    index = np.where(y_train == i)[0][0]\n",
      "    plt.imshow(x_train[index,:,:],cmap=plt.cm.gray_r)\n",
      "    plt.title('Training: %i' % y_train[index])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAADeCAYAAADLujArAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvWmMZFl2Hvbd2Pc198zaq7urups93c0Z9NBDSJ4BOSN5\nTICLDZoSNKZMCDK8CAQp/RFh0SJtyYtsgpJtQqYJQaYkUoBIiOBoQAEcDkkPp6dnprs501t1VXdt\nuUZGZuz7dv0j8rt54mZEZlZVZkZE1vuARGZGvHjx7nn3fvec75x7n9Jaw4EDBw4cTCdc474ABw4c\nOHDw+HBI3IEDBw6mGA6JO3DgwMEUwyFxBw4cOJhiOCTuwIEDB1MMh8QdOHDgYIox8SSulHIppcpK\nqZWTPHba4djlIBybHIRjk4M4bzY5cRLfa3Bp76erlKqJ137qUc+nte5praNa67WTPPYkoJT6O0qp\nTaVUXin1fyulPIcc+1TYRSn1klLq3yuldpRSrSOOfVps8teVUm8qpYpKqYdKqX+glFIjjn1abPJX\nlFK3lFKFvTH0G0qp0IhjnwqbSCil/kQp1TvWwVrrU/sBcBfAZ484xn2a13CKbfsigA0AzwJIAPhT\nAL/k2AU3APw0gB8F0HL6igaA/xLADwDwAFgC8DaAn3vKbbICILX3dxjAbwH4R0+zTcT1fwnAnwDo\nHuv4U76YewA+Z732ywB+G8C/AlDcu+BPA3gdQB7AOoBf5Y0A4AbQA3Bx7//f3Hv/KwBKAP4MwKVH\nPXbv/b8M4MO97/3HAL4O4EvHbNu/BvDfi/8/D2D1abeLOMdzeDQSP/c2Eef6OwB+x7GJOU8UwL8E\n8G+fdpsASAK4tXf9xyLxcWniPwrgX2it4+iTYRvA3wKQAvAZAF8A8DfF8fbeAD8F4BfQb/Aq+jfx\nkY5VSs3tfffPA5hBv3N8ih9SSl1WSuWUUgsj2vACgO+K/78LYEkpFR3Z6qNxHuxy0jiPNvkLAN47\n5rHDcC5sopT6C0qpAvrE+yMAfuWohh+Cc2ETAP8QffLPHt7cfYyLxL+utf4KAGitm1rrN7XW39Z9\n3Afw6wD+ojje1g//jdb6ba11F/0Z/OXHOPaLAN7WWn9Za93VWv8KgF1+SGt9X2ud0lpvjWhDBP3O\nRxT3vvtJSPw82OWkca5sopT6GwC+D8D/ftSxh+Bc2ERr/ada6wT60so/AvAkuvPU20Qp9RqAT2qt\n/69HafjIRNwpY1X+o5R6DsD/BuD7AYTQD2HeOOTz0gg19An1UY9dsq8Dj9aJKgBi4v8Y+jN2+RHO\nYeM82OWkcW5sopT6CQB/H305oPConxc4NzYBAK31hlLqq+jLIa89zjnsa5k2m+wluv9PAP8tXzrO\n54DxeeJ2ePJPAbwD4OpeOPSLeIRGPCY2AVywXlt+hM+/B+AT4v+XAaxrrZ+ExM+DXU4a58ImSqkv\noj9I/yOt9a0nvJ5zYRMLXgBXn+Dz026TFPp88jtKqU0A30Cf2zeUUp8+7IOTUiceBVDUWteVUjcx\nqF2dFr4M4BWl1BeVUm6l1M+ir2MdF/8vgL+hlHpOKZVEXyP7Zyd8jdNoFyil/AD8/T+VXynlPcHr\nmzqbKKV+GMA/B/BjWus/P4Xrm0ab/FW1V3utlLoM4JcA/OEJXt9U2URrvYs+4b+MPpn/yN5bnwDw\nncM+e9okftzNyn8ewE8rpUoAfg39TPOo8xx1zmMdq7XeBvCT6CdTdgBcQb/0qwkASqkre3WoQ5MQ\nWut/t/fZP0U/gfEhBpMhx73GwzB1dlFKXQNQ3/uMa+/v4yTxzq1NAPx36Mtt/17UN//eEdd2nOsn\nptEm3wfgm0qpMvpj6B30SzGPwrm1idZ6mz97n9da66zWunPYxSmtnYdCAP2VWejXff+E1vrPxn09\nkwLHLgfh2OQgHJscxFnZZFLklLFAKfUFpVR8L/z/ewBaAL415ssaOxy7HIRjk4NwbHIQ47DJU03i\nAH4Q/RVgGQA/DOBHtdbt8V7SRMCxy0E4NjkIxyYHceY2ceQUBw4cOJhinEWd+IFZ4jgTR7fbRbvd\nRqPRQKPRQL1eR6PRQLVaRbFYxP379/HNb34T9+7dw+XLl3HhwgUkEgkkEgm4XC643W4opeByuVAq\nlVAoFLC1tYX19XVorRGNRrG8vIybN29ieXkZgUAAgUAAfr8fgUAA4XAY4XAYHo8HHo8Havh+RTaO\nW8J0IjPn7u4u7t+/jzt37uD999/H1tYW/H4/fD4fXC4XlFJQSkFrjXq9jlqtBpfLBZfLhXA4jGg0\ninq9jnw+j1qthlarhXq9jkqlgitXruBLX/oSPvvZzz7pZT62TUb1E6UUer0eer0earUaarUaGo0G\nms2m6Sv5fB6ZTAYPHz7E7du3sba2BpfLBa/Xi1gshmg0CrfbDZfLhXa7jVarhXw+j93dXUSjUSws\nLODGjRt45ZVXsLS0BK/XC5/PB5/PZ/pHIBAwdpbXdoI2GWqXkQdqbexQrVZRqVTM762tLWxtbWF1\ndRWrq6vodrvwer2Yn5/H5cuXMTc3h2QyCaUUKpUKstks7t+/j7W1NWQyGZRKJWO7q1ev4tq1a7h+\n/TquXLkCv98Pv9+PeDyOWCx2XBvYOBWbDHxof2m76UOdTgedTgetVguVSgU7OzvY2dlBNptFqVTC\n/Pw85ubm4PV64fF4UK1WUa1W4fP5EAqFkEwmMTs7a7jC5RoUNx7TFgOnOOqAcS32ORL1eh2FQgGb\nm5tYW1vD2toaNjY2kM/n0W63US6XsbGxgUKhgFKphNu3bw8QF38AoN1uo9lsmhvo8Xjg9Xrx8OFD\nfPvb34bf70c4HEYsFsP8/DyWlpbwzDPP4Nq1a6ZjTiLq9ToymQzW1tawtbWF7e1tuN1u816j0UC3\n20Wn0zEkTjIKBoMIBoOmMyul4Ha70Wq1UC6XUalU0G5PbmTc6XTQbDbx8OFDfPzxx1hfX8f29jYq\nlQparZb5qVaryOfzqNfrqFaraDQapp/wtxzcPDcAc/5IJAK/349oNIqZmRksLi7i+vXruHDhArxe\nL7zek6ygfHz0ej3kcjlsbm7izp07uH37NrrdrpnsKpUKarUa2u02Op0OGo0GyuUyPvroI3MOTnTd\nbheVSgXNZtMQvt/vh1IK2WwW1WoVH374IQKBAObm5rCwsICXX34ZL7/88kkQ16lBXht5pF6vm76S\ny+Wwu7trSNzr9SIQCMDn88Hv95txRfKX54rH4/D7/WfepokhcQ4keg7ZbBaZTAYPHjzAxx9/jLt3\n7+L+/fsoFosD5NzpdFAsFk2nJFnLGZfHh8PhAUM3Gg0UCgW0220Eg0HE43GsrKzg0qVLhgzm5uYw\nPz+PSCSCSCRyYKYdJ1qtFgqFAnZ3d1Eul1GtVqG1NjYpl8tot9sDEQ29Sf4w8ggEAgiFQmi324bw\nm80m2u228VgnAb1eD91u13hLH374Id5//33cv38fGxsbKJfL6Ha7UErB6/XC5XKh1+vv6MnJjARP\nsH2hUAihUMgQWLVaxf379+FyueDz+RCPx7G4uIhLly6h2+1Ca414PI5oNGrsOQ5ordHtdtFsNpHJ\nZHD79m28++67ePfdd83kzMjF5XKZyLLX66FYLGJnZwflchm1Wg1utxvRaNREGT6fD+FwGMFgEH6/\nHx6PB/V63RzfarWwuLiIlZUVRKNRLC0tIRKJIBQKTUyfIcgD7EP1eh2lUgm1Wg3dbhfVatVE7YVC\nAeVyGYlEAq1WC263e2DTKekc0Rnwer1QSsHj8Rhn6iwwMSROo9y6dQtvv/021tfXkclkkMvlDCE1\nGg1jIKWUGTQ0LEm90+kY8uGxNLLf7zcGpkfe6XRM5y6VSrh37x6KxSLef/99LC0tYWlpCa+88gpe\neeWVsQ3UYWA4CAChUAixWMxEHeFw2AxU2pbkxh+Xy2VC4WAwiEAgYM5Nz6RcLiMUCg28N05QUnvr\nrbfw+uuvI5vNGg8T6NsBgCEvGZ2lUin0ej1D4nyd/YQ/WmtDeiRrpZQhyXq9jlwuh9u3b+Pq1au4\ncuUKFhcXsbBwVnuCDYJyWaFQwIMHD/DBBx+gVqthZmbGjA1J4i6Xy7xO+a1er6PT6ZhxRWnA4/EY\nAvd6vQPkJO3XbDbx0Ucfod1u4/nnn8cLL7wwcSROtFot1Go1lEollEoltNttM0G1221Uq1W0Wi30\nej14PB6Ew2FEIhFEo9EBovb7/cZJqFarAPrRWyKRQDAYPLP2jIXE7XCLHnihUMC7776Lr33ta1hd\nXUUul0Or1YLWGm6324SubrfbeBNykLKjcpDyM7a8Ir8/GAwOEB014fX1dQAwgzMSieDmzZsDxDBu\n9Ho9NJtNdDodeDweQ7TdbtdEG71ez5CQUgrdbteE2FprY1P+0N6UVYrFItxu98SQeKlUQiaTwTvv\nvIOvfe1raLVaCIfD8Pl8pl/IfAjzIwyLOWm3223zPo+hbZrNJmq1GjqdzgCZM8IpFovY3NzExx9/\njEKhgFarBY/Hg/n5eXOdZ9k/ut2uuaa1tTU8fPgQoVAIiUTCODV2P2C7OYm32+2BMQJgwHaMaqS9\ngsEgfD6fiVoo6wWDQVy5cgWhUOhR8klnhna7jUqlYqQUoD/5e71ewx/MrTAqZf+XfSkSiZgx2Gq1\njJ2l03MWbZ8IT1xrjQ8++ABvvPEG3n//fWxsbJjQn3qj7HiSuPl5+VsO5GHEbYPehAw9ea5arYbV\n1VVsbm5iZ2cHQF+WOctwaRSo6eXzeeONNptN06nYsbrdrpFOSEr8kXYFYCaFZrOJbDaLzc1Nk7Qa\nN7TWePDgAb71rW/hwYMHhlyCweDA/R7WV2TUAsB4mryP9Fbb7baJWDhh93q9AQ+dfaPT6WB1dRXt\ndhuJRALPPvvsmYfSQL8fPHjwAN/73vews7NjCEnajROR9J4ZnUaj/Y03+RnKT3Ls2LZlG3u93gGZ\nZWtrCx9//DEWFxcxOzsLj2ciaMaARN3r9czk7/V6obU2BFypVPDgwQNks1m88847WF5exvLyspFV\nZ2dnEQgE4Ha7jQzZaDSMnNnpdIyNTxtjta7Ul27fvo0/+IM/MPouwzg5yPgzLBklj2EYKAfcsOMJ\nm8jkdzBjvbW1hUwmY6SHSSLxQqFgKjRI3tTCJSmxo3JA2/bp9XomadNsNrG7u4tMJoO5ubmxtM+e\npHu9HlZXV/HGG2+gWCyaioFAIGCIehgkQTOqI0HTAyfJU5Lj97NvyOuQmign9+eeew71et0M7LNE\nt9vF5uYmbt3q76vFBKQEbWC3iRIjE96M1ngs2yqJXY4XrbUhQnqvuVwO6+vrCAaDSKfTZ2qLYZDj\nniRLZ4UEzj5B6ahareLBgweo1+toNpumGufSpUu4fPkyEonEQIRaq9XMsXRAObnZEc5JY+wkzpB9\nd3cXpVIJnU5nQLdm52FnYjlYu9023qTEYcZiR+ZxvHGyI8vPy+To9vY23nnnHbhcLiSTyYmoSGDo\nz87DRKQkcianpA4qSU16C5LEu90uWq2WqU4YNzg4KpUKKpWKGYBsF4AB0uFELEHSll66y+UyMors\nV3Zi3PbuSYIk82w2izt37mBxcRFLS0tnm9jyeLC8vIznn38e6+vr2NjYMIlWj8cDn89nJnRbZpLR\nCr1TGdHyuGFaOD/LCZBJ0YWFBVy7dg0zMzMT4ewQTO4zvyarlZiIVUohGAyaogH2JSm1VatV7O7u\nmvxYs9k0zpTL5UIikTBVTOl02uQdTgtjJfFer2fCr52dHRSLRWNQvk/SZUfhQKZmSSMD+x617XXI\n76NXSm+d1RmxWGxggMrJgST+7rvvYmZmBjdu3DhDK42GJHESEH/T02B5FNtEW3FClPZl8m7SSJwa\nPbVXJpFku6RnaEcacuIeVoZKIqYXzgnAJm1O+PI1fmZnZwd37tyBz+fDwsLCmZP40tISOp0OKpUK\n7ty5M5BHCgaDpm8AMNcm20jvlPdaFgXI43k/pNxEcrRJfBzldqOgtUaz2USxWESpVEKz2USlUkE+\nn0ev10MsFkMoFDLeeLvdRqFQMDbkmODncrmc6ZesaMnn8wCAaDSKxcVFADDJTykLnzTGTuL5fB4P\nHz5EPp83szmz5MBgKORyuZBKpXDt2jVEIhGzEIceBweUXbtrJz75Qx2rXC4jl8uZOmp6WXLwsxrh\n5s2bE1M/TW2PmrfP5zPtYukUvethlRdSYpLSglJqQG9vNBpjbSdD4EajgVqthmq1au6RlNZk22Qb\nbdhaL70sWzbgbxK/rGDhBEK5iguvlpaWRso6pwWXy4VYLGYqqZaWllAul7Gzs4NEImESdvyRMoLU\nx2lLe7KTpM2+IaUpJvQoNVy+fHkiPXBWo7A/03ljlNdutxGLxczEFwqFTJIzl8thdXUVwWAQCwsL\nqNfrhge01mbxFyWWUCiEcrmM9fV1VKtVxGIxs4DwpDF2EmdZFBfxcMDKTiCJJpVK4aWXXsKVK1cG\nSn+CwaDx0Pm61MjppdHr4gy6vb2Nu3fv4u2330Y+nz+Q6OJ353I55HI5ZDKZgQTZOEHC7vV6RssD\n9uvn6VlRNpEJJhnBAIPyklIKnU4HpVIJ+XwezWbzzNtmgxMuq4eoh8t7Kr3oUbKKnQSXk7t8TcLW\nkWVlBgksl8vh/v37uHnz5lhIPB6PIxAIYHl5GRsbG/joo4+ws7MDj8eDWCw2oPszoUeHhffdTvZK\nm7LdLpfLJMxpJ06AKysr+MxnPjMxiX+CHji9cK21icLdbrfJe3W7XZMUJhFzHOVyOfR6PVOBRIfC\n5/MhGo0agubkDsBUv1Du5Erpk8bYSTybzeL27dum8gMYTFBKCYQd8vr167hx44bRgLvdLhqNBpLJ\nJFZWVlAqlVAsFs0iFjsMZBInHA5jdnYWoVAIDx48wMOHDwfCcZkQ5M0oFosoFApmQcQ4OisJh5NR\nt9s1iWCp8XLAkdQ5kKU9WSvPRIzUB1kzO+7IgyWoOzs7qFQqhpxrtdqB+wVgwFuWC5okcckqC1te\nYf9jPXGlUkGxWDQDEYAhN9n/mE84a/C6vV4vVlZW0G63sbu7i2KxiHA4jGq1agiayW1Gq9ImsgSR\ndvT5fAN2BfryjdSKKUXMzc0hEolMRL5IgjIIJy8ZhSqlEAgEMDMzY5xErTU++clPwu1243vf+x7e\ne+89E3GEw2EsLy+bclxOBjI5Kh0hjtNKpWLWcciJ8iQwdhLf3t7GrVu3UCwWB7woAAMzPQdeNBrF\ntWvX8Nxzz5m6VM6us7OzuHLlCt577z1sbW0hHo+b7DgJrNfrmXApFoshnU4jFArhm9/85oAHR++O\nHZ96bLFYRD6fRyqVOrD44axgRxSsEyeJ034+n8+EitSS6ZlThqJHy6X4Ho/HlEq1222TexgnuJiC\ny+rZdpn05sBk+xnWRqNRxONxs7KSMpxcb0AbyJLCbreLcrmM3d1drK+vmzyDTIZSZ5a1wnaEc5Zw\nu91YWVlBKpXC22+/jWKxiEgkgmq1emCvF7abSX1ZgSMj32EyJCMgtjeRSGBlZQUzMzMD55oU0JsG\n+hIK/2c7A4EAEomEcfpcLhd+4Ad+ABcvXkSv1zOrdrXu77l04cIFU5ZJsC9wgrQT5kyitlqtAUfi\nJDB2Ei+VStjc3DTJKWCwikQmpzhwmWh4//338dZbb5mFPSTaN998E2+++SYWFhawvLxsNkSS0kMi\nkcDVq1fxyU9+EsFg0OiD8nuAfU2UIVar1cL29jbS6TQikchYVnBSC2dIy2sLBAJGYpFVBxL0DLjN\nQCAQMCTOAUiZQNp/nKBccPHiRbz66qvw+XzI5/NG9280GohEIpibmzNeIe1BbZMrUll+Z1edDBtQ\nHOzPPvusqfy4e/cuNjc3TRTIhDA113FIT1Ii8nq9ZmHaF77wBXOdUte2F0XJ9QI8jyRzWTDA/6Wz\nlU6ncf36daTT6RMlpyeBzJFw0pfSKqVFtp1/M6cWj8cNaTM65YZXiUQCfr9/oJpHttuWb3kMnalw\nOHyi0crYSbxSqWB7e9sYiZ3DTryRuDhwCoUCvvGNb+D3f//3TcE967m/9a1v4Y033sDly5dx/fp1\nsyMbE33RaBRzc3N47bXXcPny5YGBLStiZHKLGyB1u11kMhksLCyMbZk1w0Nq3SQrv9+PRqMxIC+w\n6oKdlR3V5/MhnU4bz0OGeAy5R9XjnzXcbjfm5uaQSCQwNzeHl156CR9//DE++ugjZLNZ5HI5XLhw\nAa+88gouXryIZDJpohK74kjaRtpI/s9BHgwGjb7barVw584d/O7v/i7W19dNhENCrNfrUEqhXq+P\nxV4cM2zrJz7xCczOzuLtt9/Gm2++aY5j22TZIOUSKTty/NmTnN02l8uFdDqNa9euTdSWFMA+Kcsq\nNk5UrN+mw8aqLFZ0Ma8mFwHNzc0hnU6bHAP36aHXLWvr7eIBFhhwDQwr8E4CYyFxGq1cLhvPxfYE\nJOnYmhzQD4FWVlbwwgsvGHlkYWEBPp8PFy9eBACzI+HMzAySyaTRxahjMXOvlDKeKG+k7a3xM41G\nA5ubm7hw4cLYtGKGaLxOqcUBg0vtOeiuXr2K5eVl3Lp1C++9957xEgAMeGYkeEoSp71Q4ThgFVM2\nmzXaczAYNJstpdNpLC4uYnFxER6PB5ubmya0lWV0wKDXOorUAQzkDCg7lctlLC8v47XXXjODXuru\nfr8fV65cGVtSTzod6XQa4XAYW1tbiEajpqKEJG7Xu8u/5WRgJ4mBfRtSjiHhTRoYSUknRjpr7N8y\n8ufYYr5rZWUFr776KmZmZjAzM4P5+XkTzUritn/4/dJbZ435SdtqLCTOWWxnZ8eE9nKhje2BS22a\numUqlcLnPve5A0udlVJ46aWXBgYWbwxvFOtDk8kkUqkUKpWKyUZzRzP7hrDz12o1bG5uIpfLjU0r\n5iTISYQ2AQYnQDlAv//7vx9f/OIX8Tu/8zu4d++eSbbIRR8sO5MkflZLhw9Dp9PBxx9/jDfffNMQ\nbzweN/vHd7td4zHfu3cP3/jGN/Dw4UPTdrkXOAlZ7qkDDEoIjF5qtRrK5TKUUmab4meeeQavvvqq\nsZfcHMrj8SCdTo8lsWdPtiy7jcViSCQSKBQKpr6e1ycnfk7kcuxRcuCEJb+DCUFWZEwieA/lZlZ2\nf6YtZIkpydftduOZZ56By+Uyy+3n5ubMYjqOM27VIccbZc1ms2nGIq/npJ2/sZA4lyt/+OGH2N3d\nHZj1pd4mpQ0OGlYltNttk1wE9ndyY5VKIpEY0Dyll1oqlYz+y/KiRqMx4LVJMpQebbVaxdbWlqlr\nHwfY0RjKSRK3a6SpcS8sLOD555/H66+/bpI7nNxYN8tKBFkTPG4pBRisE+ePDGPr9bqp6c3lcibi\n4g9X5cmNvrjE3K5cAg4+kIRyivTo6KHzp9FooFgswu/3m/3nz0ofHvYdcjUySZbVFLbmzf4jHRbm\nWuhBSs+Vx3Ef/kklcd5HuYOnjDIADI3Q5G+v14tQKIRIJGJySHx/VJRq91cWDLCvngsSbzabuHfv\nHr797W9jbW3NVFcAOEDiwOBy6W63i0KhgEwmM7DJPQcZ9WKu/pR1sDwna42ZbMhms9jd3R1Y0cab\nLxOr1PB7vZ7Zw3wcoARAb1nuFCcrV6iZ0/uUshAji263a/ZODwQCA5OXHUaPC4y8rly5Yvaw4Z7P\nzIMkk0lcv34diUQC3/d934cXX3zREHG1WkW9Xh+Y2OzIxR7cWmvz9BY+QAMAstks1tbWjNTCAcoH\nl3z+85/H5z//ecRiMTNRTALoGcrVt1J2I8EBGBgztlxAUIK0N9uaJEhNnGO11WoNbKxn58A4UXG8\n7O7umu0UtNbmfnNSk7q3HcnRqZT5qtNYAT02TZw1191u11RISINwFqUnSRIvl8v44IMPUCqVzLJw\nhjcckPKRapLIeW5ZDuR2u83G+HJxCG+GzN6TELml6TgHKDueJHGZRJEehR0iy6XAcnETqxjspPK4\nSZzeYLlcRrlcNve+3W4jk8lgY2MDpVIJSiksLCwglUrB5/OZfsGtCWzN226rlKAAmGXYtG+z2cTm\n5iYKhYIpzYvH4wgGg+bRf8VicawVPfJ72WfZV+WKVAlZnQHggORg5xX4Htda0GMfdd5xwZ64+L+0\niQ07kSujXll6KSN2O/kvJw86B3ZZJjC44OxJMBYS93g8SCQSWF5eNsuouZiGCRjOZnLvD5fLhWw2\ni69+9asHJBfZOaU3b4c9skKDRMYstVxCLGuQgf3d3paWlrCysoKVlZWx7g3BNtFjssNCRjalUgnV\natUkkFnNwsmRZXey1llGGJOQ2KQm/sd//McmRKWcwfJDANjY2MDa2tpAMmvYcvphbRqmjXNA895z\nIyPuZEkSm5+fN4n1q1evGmI7a7vJSZf93+fzmcfLyfYB+x63TeK0j6zooGMkv4Pnth/OMgl9BthP\nbGqtzdYD5BXmMHiPbY+acl0ikcClS5eQTqdNaaGMgm3FQDoGdACYSOZ5ZQR0Ehgbic/OzuKZZ54x\n2e1CoYBisWjqfrlpu+xkSilUq1VkMhnznvScbPKW2jDfl7MnPWsu/GGo5PV6kUqlTITAsDkQCODC\nhQu4dOkSLl26NPYHJUgPaZTn1Ol0zJNKpERAcD9pucGP7c2NG1prlEolbGxsGA+HZMpNlxi5lUol\n7OzsmEeN2WWGtjfJv22vSspSDK/D4TDS6TQ8Ho95BikfvOByuczkOCmeOACzLNwmcUnmcnzZuSC+\nLkmcr7MqjA7DsHOeNeyCCMoXHAvs3/Jh4sNAYuYkzUfOScVgmLM4zLGU/UuWPMr++CQYC4l7vV5c\nvHgRkUgEzz33nPEW+Yy7UqmEhw8f4u7duwNb1NJrTCQSRosbtm84YYc5Egxz5IystTYla6+++ipe\nfPFFcwOY2Y5Go4hGo4bkxwU5WEYlV0hsMqSk/biKzOv1IplMDqzelOV5k+BVuVwuzMzM4NlnnzVP\nI+fimng8jtnZWbN/RbvdNjIdvWWCNpPeECHbaZfXAYOLnmq1mtnvp1wuI5vNYnt7G9ls1vTtubk5\nxOPxsT46/QqxAAAgAElEQVQQQSllJB/2VUYnTK7ZcqWUAexEP38D+96+JMJJSYTL1cyyLzebTZRK\npYFqODtikhEZOYL2sSdAW75klC93ACVh87qkvHdSW9SOjcTn5ubMwwaoecqNaj744APE43HcunUL\nd+7cMUlHekT0jEnits40DLZOLLUqyg1cVvvaa6/hh37oh07TDCcCSbTDanv5w7ZziTGTgnzABTur\nXLnK848bLpcL0WgU8/PzaLVaKBaLqFQqKJVKiEajiMVihjS11qaUjjKC7R1JjVPKcLQdvU7ahR4U\nB+D29jbq9TrW1tYMOayvr2N9fR2vvvoqisWiuZZxwpZTeF/leGHylW2X7wH75XLA0X1h3O0l2AZK\nJ0C/HdxGttfrmW0IgOGOkPSuZaWWHeXbeYZeb//xbixXpjzJMcnH/w2bRB4HE/PcJPkEjGAwaDTq\ndrttVsgBg4+akom4YR3N9srtCg7pZXS7XbjdbiQSCSwuLk7k4gUJSdxSeyP5UN8G9jf3B/oknkwm\nsbW1NVCV4ff7zWOmuMfKYZHMWaLX66FWq2F3d9fo4axRTiaTWFhYgN/vR6lUMtvnsgqBkzT7h619\n2pCTom3fcDhsNvtfWFhAqVRCOp1GMpmEx+NBMpnE5cuXMTMzg3A4fCKh8pNCRpHDKkyAwSdsyQVg\nsoqD0ZwkLemFTiKktk8vuNVqmcT+MDlFOnqcwMhFdBiB/SSp3KLD5XKZZ9Pm83kUi0Uotf+wDUb+\n3W7XRMEnsavh2J/sQ8id57hfQSAQwNbWltmJUCZgZIc7KlFgh82yRI+fZR0pvbpQKHRo55wED3UU\nkbP0iV6IJPFgMGiWpcvJj8RIkpR7JY97kNK73t3dNYsnWGXD+9Vut5HL5YysUa1WB0jKxmESgCR9\npfZL6RYWFrC0tIRUKoXZ2Vlks1nEYjGjl87OzmJxcdHIF+PoI3Z7ZFJS1oPbUpnMH9H7ZE29lFjk\n1rRyHE0a5NigNyy3oJBrRw6TYO1kpPTEZeki7c5FdIwW5Vjid3Y6HbNl9knYbmI8calB2Z4QtVoe\nd5gO/KgDxyZ4ViLIpdPjTtYcB1IikuGf3PAIgHnuYSQSGUj2eDwek8SjBDEpe0Jrrc0mZhw48jFt\nchMvkpUthwAHN24adT+lg0CPjVIKADNJcqvacrlscg/FYhHVatU8X3EcGJa05aIVkjr7OeUU2U9Y\n2ss+RU1YrnzkZyYR0iljVYpcGMcN4+gVywlMrpEAMDCZsd1yspP9C9hPqPZ6+7ulytwMpTzpwT8p\nJoLEbUlELqGndz6MxE8i6WYnaujhye/jjeU1TSJsEudr0kOnVJVKpQyJU6OTi63Y4SYlsal1f1FW\noVAw7axWqyiXy+h0OmbZu9xSlv1GEo3MF4xaxALggJZKwiaJM6xutVqo1+vweDxmQyx6YOFw+EQ3\nOToOhk1QksQZHbBPcFzRBrL6RMqWlFVkzfMwu01KYlPeXzonsjpJkrhMPPKz0qGUTqRN4rKkUH5e\nkjiLMWStvoxsTgITQeLsaMD+Mlifz4dYLIZYLGY8LXYSmWzg520yPs732ckKztzy6Ry2pz4pkJ2N\nHUM+bksm6SSZhcNhLCwsIB6PD9S52t4EcwSTBt4XtpHtk3Xhdv7DvofytWH9xdbMpefF2noSHleF\n8vuZPEskEmdOaLYMAOzveMlJxk7mS++UyU/5rFFgX47jAis+cJkLr+T2u+POA9ALp4Yv+7a0Rbvd\nHrrOQ07ssh90Oh2zU6UcZ3Y5oSyw4F4pXAejlDJlqHI1+JNiIkgcOLhSih2Kj16zPfHDajyP812y\nZEgOfNsTl985aZAkPkwC4I8k8Ugkgvn5efNgaBkF2QsSxj0gJaSHKRc40eO2bcDP2D+S3DlY7YVi\nUv+U4bYkcfYfkjiP4RoH7jdy1rA9cVnWJveQIcnxeOr+LpfLrGhmG2Q9M+3i8XjMClom0CdljDAf\nZOv1JHEuaBtGonaEwfZy8pLbNFPflv1ELpSj/MS1LwBMNdio1bOPg7GSuG0s/iZJy4oLWeokdaij\nZrNhiTk5Adg3+ij5YBI66jBykhU7cpvaUChk6uqB/QQmtVBJZrZXPglSisSwAcdJ9zBPXB5/GKTG\naXtiDJ9ZxcO8ie1MyG2CxwFbUuFCNa5t8Hg85qk0vEaZh5KSJuUXRsG0rdxEjI+km5R+QsKt1+tm\nibvs0/Y9G5YnYT+w1wrwfXulpvxuOdFTxuE56HRwQjipB4hMhCc+zFNi55EapyR4mYwYReLDwkuC\nnoVdSvekXv5ZYRiJM0nJVWpKKVMWFwwGTQdkpCFJHJiMp/iMgt1eYJDE5cMw5GeOk8uQdpAkbn+3\nUmpgyT2dCznZkcTHWbUhJzD5KMKZmRl4vV6zyyJlESYzue0F2yUXgCmlzGrHcDgMv99vPMxxP77P\nhk3ict9vuW01cJDE+ZosECCkB247O/J9kjjtKxdLud1uszGWvTr6cTERJD4MNIxdrWK/P8w7G2YY\ne2DaBHbYZDBpsGUUhrfSM+LrLMPjwgZZ/ysrEOwJ0fZGJgX2faKnyac22eRpD7Rh/WPYvR81uGVk\nOOo7xjUZDrtP1WoV2WwW7XbbbC0Ri8UMEVEPp+Yrozhus0sHql6vm0Syy+Uyj0Os1WomwTusIues\n+49c0NXtds3CG+5kySiDuRQ6PMP6hv06iZh5KI49KdWwPJrv93o9893yeria9EkxESQ+ingledtE\nPur4YZBSzajPytcnTUawIUmcHYV7iTAkpvdh753BcJI7GMrSKulxksBtb2TckNfKJFMoFEK5XDba\n5GGTuOxr8vcwL39YP7BtYk968nyTgHK5jLW1NXS7XfOg6Hg8bpL3lEWYlKUWTi9erjuoVCpGV2eF\nBbfLqNVqQ3NXZw32D+nk1Ot1FAoFsw89J36fz2fKVOnUyAgfOMgFUk6hp80dM+ld06GSazG4ipiE\nfpIPh5gIEh92w2V4SolAHj+KkI/bcWyykue1B+EkkZgEQ3fW9coyJpKZfJI3MKj5yTpZ2WmH6X2T\nBHlvpFdlE7w9AGVUNywyk3/LKEW+x/OzTM+uQ+dEcpbe+LDvYYVJoVDA9va2WR3IR4Q1Gg0TqTFf\nQiLiil2ZEKcHySSm3Ewqn8/j3r17WFxcNPuujwv2fZcyI2vc5X2jx25HEDKqo+ctZUuZO2B+id4+\ntzng1gtcxclSQ/YRPnOTD9Z43EKCiSDxw8Awr9FoHJAATmKQSA8KOFheNslgR5D1y+wgJBIus7dX\nEDKMZkKQYSbPe9ZEdBRGTaSy3hnAgclHErbtLdsSyzAil2sEZITD3MKw8syTrAF+FMg2tFot8xjC\n3d1d88APlr2R2ILBoCk35eIlPvCEyVv5dBzpPLEMNZvNmge7LC4ujj2Ste8z+zO9ZvlINrkrJiEn\nYmB/cRfvLbV2mZMhiXM5fSgUQjweh8vlwsbGBorF4sADvAGgXq8jl8sBwAGJ7lEwcSRu33x7tpTh\n0jDtc9T/NoatDpX6sLyecYWGR4G24Z4QMpHDASeX2UvQg2ASlPtDTHKOYNg9YHhLGYn37igiGUbg\n8jP8mwMYGBzcfr8fkUjEOBi21DdO22nd37p3a2sLlUrFTM6yWoJeYLfbNcu/6YXTE+diMO5HLxe7\nUKrz+XxGS8/n82a16jgfmmI7YhzToVAIyWTS5ARsic3mE9kX5HkkgUviZQEGJxHuK5/NZqH1/oZ7\n/Aw99FAoZJLNj4PJKQQ+BDK5NozEj0Pgw+QCe8DL9yaNwCQkYVBu4uBjbSrbJknc9sRZ70xPCxi0\n9SROXKNge0/ydf4+rgQnvXYpt8kQOxgMmocE2InNcZG4bAclDj5zNhwOm0mJoTvvOXcElYRE3ZhP\nNwJgViCSqBgFUfMtlUrI5/Oo1WpjGz8cv9wcT44TPrgjnU4bG8iVmMNyIvYqX74vV65SYopEIohG\no0YxoC5O+/J1XhNVBl7r42IiSPww0hiVYDqq0fbAkq/Ln2Ghlx0OTyKZ2SE+F3Mw0cn2+/1+RKPR\nA/sWM+RjeRlXscm2y048bpCAhuUv+L+MQI5KcvOchx1jf6c9OcZiMbMcXX7nqMnitCDHCAmnXC5j\nfX0dtVrtQF27XNSltR6oKpFjgp62XP3L9sqd+WgbmUCcBCfI9paZ5OfEZPdvu08NKx8FBmvNaQvg\nIImzHFWSN69JLhh7UqdxIkj8sAbYA4mv2fqlHc6OyjBLycQOo6kZnsbDTE8TslLF9kTZYeyH2Xq9\nXvNoLdbV1ut1s5G9PcGNE9LrG7YxGTC4s+WwGt5RSUx5nmEDSnriPEap/vJpDthh3v+45ZRqtYrt\n7W2zb7U9GQ3rL7ZzAxzcg4XL78vl8sBCH5/Ph06ng1KpZFYnjgtsLytv7D117MlWgnYB9u89yVa2\nlZEMZUyl+msyIpGIqfziI/0ADKwS5WRCgn/SCrCJ08RtyM5DouXrssON8riHwfbG7NlWPsx0GsAO\nZu8XoZQyIbCdfacnznCYmzkppUzp1CjbnmW7+JtELknH9qJI4vaeL/L6R0Vo8j15ftsb47VwFaTt\nidve3FmCNmCVCZ+0zrbIlc/yOqXmPypSkX1BLuUngbHWvFwun9gilseBHM+ShCWR28URwzxx2wGU\nduJye5kwdbvdxtZceCZLOFlbD8Bci1w0NvUkLsl51PuP0kj7ZhzVoWRYJSsQpgHsXHK/ZHoS1D+H\nkbjH4xkIs7kUmPt/yLKqcWLUAh65u6Wd55BlfxL2oB2GYSR/GIlzErT113GROBOWvV7/6TVciEIi\ns9slZRUZfckJ0r4HJEbuiy23dT3J+ucnhewPJFLpRcu9wAl7S49huTM5+XEC4/EAjLzC0t94PI75\n+XkTCdDJkIupngQTQeLHIdlHPd9xBpE925LESWaP+/1nBVsGsElc7httyyKUWfgevXl6WdLrHbc0\nMCzkZ2JWEpO96hQY7oXL1+222VKC7UBITTwejw/IKZPgiXM7XCbyOBnLrSuGTTr8vO2h2kk9khYn\nr1qtZjx8ueqT1S3jjOTYJimvsL9L2VBCXq8trdnOAl+zSZhjiHkDPsib5cC0y0ktppsIEj8Kj+pZ\ny8/YkANNviZDxXHV+T4qbD1f6sL0PuT+HhKSxGWYKVdwyu8YJySp8tp4/ayqGBUGH8frtr/D/ozM\nDXCiCwQCZuXjsE23xjXx0ROnzMHrkRGmlAHk+/zN5eBSIrKTukxkkgzloppGo4F6vQ4AJ/Ig4EeF\nTcSyLFCSOGUPiWELwqSUS4KWSV35FCxgP/FJO/h8PiQSCezs7KBcLg9shHUSe89MDYmPItXHIZhh\n8o286dNA4jK0lVEEBygXITBxYoOaHOUUSVQME2UHHhfsBBsAs4iJD7t9nOXuNuHb3zfKo6d9JYkP\nS6SOA1r3VwdWq9UBScOe4OWGULZTY5O4XbmltTaVFVxJzfHCXAr1eO52OA6b2BMUSdfv9w/s9mnD\n7u/0tOX9tx8YYssylC6Zm4hEIggGgygUCmi32wPL9odtmfuomAoSl3iUxg4jf0ng9iCVHXaSIQeU\n1Dr5OklmmBZO8KEbrB8fVjN/HG/2LCEJhw8uHuaJywFsSwX2uezz214/MLjTJeWqQCBgSjTl+cfp\nhfM65DoKWc8sk3F8jwQlCV1uLSuPoRQQjUYRCATMs0xDoZAhfuZUGo2G6YPjBm1AZ4ZtIpkCB3Mh\nw/o/x4jUzRm5K7W/ORq3gOB55VOmpAfP63jSCrCJIHFbnxxFGscZIMM0TmKYsaT2Nwnh8HEgE03c\nw0OSuJQbDiNxDkZgeJvlxDZJ0FqbvUC45JmvA8NLSodpvfY55WfZdkmI9Da5YRInUGk3OXjHpYvL\nCiVWSDCRZ5P4sAockpJN9NzeIZlMIhqNQqn+UnNWqdArJYlPyha1tAHbIdt+WP+wI1FJ4rJPSP1f\n9gl+F6Nie58d6eU/iaM0ESQ+jHjljEiDjyr7G2YAOYiPMpA9sId5bJPijRIkF7uD2Xt7jMp8SzmF\nRC3PdZhGPC7I6+AiJibv5ACiB2h7ObYENSwik9/F17lugJ4UN4di4ti+vnGt+GWkwI2qeM2hUMjs\nNCjDd7lDob2SkL+l58iNsxYXFxEKhQb6j5wcuNnUuJ0h3iuPx2PWRDD5msvl0G63B6IpmcjnGJD3\nkt67x+MZ2DNeetT25E/OsqM8uw8+CSaCxA8DB6ec/UYdJ2c5OesdRsL2zCuTPJMKO2yXXjgH3rDH\nzEnwYQEchLaGOEyLHifkdWitB+QgOXjYLtbAU2qSnx/lhUlIL4ubQ7FihyQun2Juh93j6j/2AxFY\nv8zngFLDZv+QFStSTpHRHttVrVYN0YXD4QMkLp9YMwljiG1gNQ1JvFqtIp/PD+j7o7xxWZVDsuYq\nZznJyT4o+5b03m0S5zU+6WQ3ESR+3BnJ1jyHvWcPSlsjPYqchg3qSSEyQk40ozxlEtqommmp4bGC\nxV4Ywd/jlFRGecuyTpzvy5WI9AyBfY/SDpPtc9uyiBzIrLyo1WrmART8bilfSPnlrKG1NjsRcj8O\nRlzFYnFgkzR7K11WM3FbX3lOCTpVrLuWe6nIXTC5adZZ24HODBevlUolhEIhs8lXtVpFsVhEsViE\n2+1GKpUynxvGLewD3PDM7XabCREY3EOFkhX7F6+Br/F1m/yf9OEQE0Hij0LgwwxtDz7bS+Xrw5JW\nw0h/3B7EUZAkPmo1qxykwyC9Cnv3NVYV8L1xT2LDSJbXaecD5Pai9BC5yZD0loZJZ/L7SIAsIeQS\na25PQMmKnqtdvjcOIqecIkmc9fQkCxKrLC1lW1hHzYqbUc6VJHEZ7TFiHieJA/t12rVaDeVy2fRn\nrTUqlQqKxSIKhQICgcCBxPcwWZVVLRwz8vGHJHGZL5Glh/V6/YCkIsleKfXEG2BNBIkfBnbCQCAw\n1Pu0w2wJ+zg7UTeqfG4SQsGjQAJnqEi5iZ1q1GPE2F5q5syay+SWTLqcRPb8SSAnVbmBkx2BhMNh\nrKysQGttyIjkJQeXLZ3ZDoAEJzlWZfj9fszMzCCZTJo9MYZdzzj7D2UNTkIABkJ/KZPIyV+u+JUS\nHDV21jzTm+UTcYaV5HFDtnFsXaGUMjt3MgqJxWJIJBJmjESjUSwtLZn7K0v8hnGEXYIrF9MxUpOy\nCScyPrCFdkqn0yZaarfbZp1GNBp9olWbE0/iXB4eDAaNnie9KXvwAIM3YhiJ2146MUofJcbtkdpg\nCCzLl+gd2lKIHZ3Ip96zM8oBKcuwxtlu6SHZk428T7FYDJcvX4bH4zF7o3ODIVvXJCTZ2vKbnMhY\nLuf3+7G4uIjZ2VnzNBypg0oPbtwkDuw/JESG/3LRj9Rv7ceL8XUuipEyUqlUQrFYRLPZHOkEccOn\ns7aDUv2NqFwuF2KxGGZnZ81ugqycUUohFAodkNv4eTlm5ETHhCYnOvYt+XmOG9sOSinMzs4inU4b\nWYvj67AChONgIkj8MJKwtU65w56cAW09Ut4UQnZau4KD4bbcl3vYtUwCkdsbEPFa7c2vbAKWJE4i\nl/aw7ScrDsYBeR02MZKs6BUlk0m88MILWFxcNINGJu7Y7mHfMUwL5/H05PnElqWlJczPz5vaaDsi\nGOcGaiTsYrFokrqSZNhO6ZHLktRoNAoA5qEQfD0Wixk5ic/YZBKT4waAkViSySTm5uYQiUTOPIpT\nSpnHpXFhD6PSSqVixoxtC/n/sOjMlsnkZDhsN0j5JCROgoFAwDgWsqDg3O9iyNlMEhZnLXoYHIh2\ncsmGnRX2+Xxm60iep1wuGy+DmBTyJrgPAx8HxSXO7Dy83mGe+LAMuVyGLVf1cdIcZsuzAgeJrV0y\n0cjrm5mZQSgUGvD+huUKbBw2QUnPWi7bJkHy0VryOF7Xk+qcjwOt+0+kz+fziEajiMViB7aRkGOF\n95fRbjweh9/vRy6XM5UoXq8Xs7OziEQi6PV6KJfLRtqk1MJIjtLF/Pw8Ll68aJ6gc9awdypkX+92\nu+Zhz/J1+/5J8D1OWDJiY7+UfY4cRAfD7XYbbZ6SnIwo5Xc8LiaCxId1djZMdjDunMbaXDlYRkkh\nchDTE+d3cjtWeuJerxfz8/NIpVJjf+DrYaDWF41GkUqlzIQkd19Mp9OG2Eadg2FmKBQaWPRDnZ1P\nJRlVpngWoMbPZfacnBKJBOLxuCkxpKxk4zQnX5fLhUQigeXlZaOvhsNhs4jqrCd+l8uF2dlZ3Lhx\nA5FIBJFIBOFw2PzE43Ez6YfDYaTTaeMRRiIRpNNpJBIJAP3nP8ZiMfOIsU6ng0QigWq1ivn5eaPj\n8qlRgUDAfN/S0pKZEM7aBnZkBAzKpKOquo6SWilX8jh64uyPPDcVArn//bCtke3vfhJMBIkfhkAg\ngHQ6jeXlZSMbcDYb5qEBGHhSie2JSU2ViUEARgtcWlrCxYsXkUwmzTWc1Ix5UmDIurS0hEqlglgs\nBqX6j4niMvoLFy5gZWXFhMh2/oCTI5M+ctOkXm//eYSpVGpsS6eVUqbuOxaLIZVKIRKJoNVqYWlp\nCUtLS0gkEmObZLxeLxYWFnDz5k3U63XUajWk02ksLCyMxQv1eDx47rnnMD8/bzRbkgiTluVyGaVS\nCYFAAIlEwnjv7FMulwvLy8sDMgTH0LPPPotut2sqUq5fv45mszmwxSodDPtxb+OE5AY6BVK3Bva9\nd+Dg1tSyeoeOIHMFbDMjGyn18nu4nkD2h5OM7ieCxO0klYT0Opnl5XJyqdfKGyUXedjfY5M4Z1V2\nxnQ6PfTp8JMEVuxEIhHE43HjgcsEVjQaRTQaNVUUwMH8AL0FWVbGwcuaYdYBjwPUCxkZ8L5TBotE\nIkO32T3L66MHWygUzPavXGg0Dk88mUyaSgwpE/B6S6USCoUC/H4/4vE42u02SqXSwF400oE5L5De\nN5OP0nuWCUkAQ5fDyyoVWSI4Sr7Ren9bDKl720n0J4Wa9FI6Bw4cOHAwGpMR7zhw4MCBg8eCQ+IO\nHDhwMMVwSNyBAwcOphgOiTtw4MDBFMMhcQcOHDiYYjgk7sCBAwdTDIfEHThw4GCK4ZC4AwcOHEwx\nHBJ34MCBgymGQ+IOHDhwMMVwSNyBAwcOphgOiTtw4MDBFMMhcQcOHDiYYjgk7sCBAwdTDIfEHThw\n4GCK4ZC4AwcOHEwxHBJ34MCBgymGQ+IOHDhwMMVwSNyBAwcOphgOiTtw4MDBFMMhcQcOHDiYYjgk\n7sCBAwdTDIfEHThw4GCK4ZC4AwcOHEwxHBJ34MCBgymGQ+IOHDhwMMVwSNyBAwcOphgOiTtw4MDB\nFMMhcQcOHDiYYjgk7sCBAwdTDIfEHThw4GCK4ZC4AwcOHEwxHBJ34MCBgymGQ+IOHDhwMMVwSNyB\nAwcOphgOiTtw4MDBFMMhcQcOHDiYYjgk7sCBAwdTDIfEHThw4GCK4ZC4AwcOHEwxHBJ34MCBgymG\nQ+IOHDhwMMVwSNyBAwcOphgOiTtw4MDBFMMhcQcOHDiYYjgk7sCBAwdTDIfEHThw4GCK4ZC4AwcO\nHEwxHBJ34MCBgynGxJO4UsqllCorpVZO8thph2OXg3BschCOTQ7ivNnkxEl8r8GlvZ+uUqomXvup\nRz2f1rqntY5qrddO8tgnhVLqZ5RSnb12sX2fOeT4p8IuAKCUuqaU+nd7bdtWSv2PI457KmyilPp1\nq60NpdTuiGOfCpsAgFLqHyql1pVSOaXUV5VSN0Yc91TYRCnlV0r96p5Ndvf+Ppqjtdan9gPgLoDP\nHnGM+zSv4RTb9jMA/sixy4Hr9u21778B4N/7eeFptsmQdvwmgF97mm0C4K8AeADgIvrO5P8M4I2n\n3Ca/DOCPAMQAzAD4FoBfOOpzpy2nqL2f/ReU+mWl1G8rpf6VUqoI4K8qpT6tlHpdKZXfm4V+VSnl\n3jverZTqKaUu7v3/m3vvf2VvJv4zpdSlRz127/2/rJT6cO97/7FS6utKqS+dsk3Ou11+BsA9rfX/\nobVu7v2895TbRLYpCuDHAPzzp9wmlwH8f1rrh1rrHoB/CeD5p9wm/zGAX9Val7TWOwD+CYD/4qgP\njUsT/1EA/0JrHQfwrwG0AfwtACkAnwHwBQB/Uxyvrc//FIBfAJAEsIr+DPZIxyql5va+++fRn/Xu\nAfgUP6SUuqz6Yd7CIe34lOrLBR8opf6uUkodcuxxcB7s8mkAq0qpP1BKZZVSf6iUOs7gHIXzYBOJ\n/xTAutb6m8c4dhTOg01+C8Bzqi+9+QD8NICvHNXwQ3AebAIMTlAuAJeVUqFDjh8biX9da/0VANjz\n1N7UWn9b93EfwK8D+IvieJsc/43W+m2tdRf9Gfzlxzj2iwDe1lp/WWvd1Vr/CgCjU2qt72utU1rr\nrRFt+CP0ZYI59AfmXwPwc8ds/yicB7usAPjPAPyvABYB/CGA36MX9Bg4DzaR+BKO54UfhvNgk3UA\nrwO4A6AC4EcA/O3jNX8ozoNN/gDAzyql0kqpRfQlSQAIHtbwcZH4qvxHKfWcUurLSqnNvXDo76M/\nk42CNEINQOQxjl2yrwPAsZMXWut7WuuHe3+/C+B/APCfHPfzIzD1dgFQB/AnWuuvaq076GudiwCe\nfYRzSJwHmwAAlFJX0PcKf/NRP2vhPNjkl9Anv0UAAQD/E4Cv7Xnlj4PzYpP3AHwXwJ8C+F0ADa31\n0CQ4MS4St8OTfwrgHQBX98KhX8TB2e+ksQnggvXa8hOe80mv+TzY5Xs42A77/0fBebAJ8dfQn+Ds\ngf6oOA82+QSA39JaZ3S/AuQ3AMwDGFqhcgxMvU201nWt9X+ttV7RWj8DoADgO0d9blLqxKMAilrr\nulLqJga1q9PClwG8opT64l7y4mdx+Ew9AKXUX1JKze79/TyAvwvg357wNU6dXdD3Mn9QKfUfqn55\n1N9GP3T+8ISubxptQnwJwD872UsDMJ02+TaAn1RKzao+/jr6RHz3hK5v6myilFpWSi3s2eM/QF93\n/xkFpLoAACAASURBVMWjPnfaJH5cD+znAfy0UqoE4NcA/PYh5znqnMc6Vmu9DeAnAfwKgB0AVwC8\nDaAJ9EPfvezzqCTE5wG8q5QqA/g99BM1/8sR13bkdVmYOrtorT8A8J8D+A0AOQB/CcCP6n4FwnGv\n7zBMnU32jvlBALPoh8jHxXm2yT/AvnSQB/BfAfgxrXXlEa7vMEyjTZ4B8E0AZQD/D4Cf01r/8RHX\nBqX1k0S65wd7XuMGgJ/QWv/ZuK9nUuDY5SAcmxyEY5ODOCubTIqcMhYopb6glIorpfwA/h6AFvoF\n9k81HLschGOTg3BschDjsMlTTeIAfhB9DS4D4IfRD/vb472kiYBjl4NwbHIQjk0O4sxt4sgpDhw4\ncDDF8JzBdzxNs8RxS5gO2ETv75/QP9He4k+ttfm7UqmgWCyi1Wqh2+2i0WigVquhWCwil8uh0+kg\nnU4jmUwiGAzC7/eb83k8Hni9XnNOolqtolAooFgsolgsIhQK4eLFi0gmk/19GVwu+P1+BAIBBAIB\nc06eQ4lFqmr4gtXHtsk5xqOUuj0tdnFsMhxH2uUsSNzBMaGUMuQ4jCTX1tbw9ttvI5/Po9vtotvt\notfrodFooFQqodlswu12w+PxwOPxwO12o9frF4UkEgkkEgn0ej10u10AgMvlQqlUQi6XQ6PRQK/X\nQzgcxt27dxEOh9Fut+HxeLC0tITFxUUsLy9jYWFh4LrkJOPAgYOzx9ST+HHkIEk4h70/7NydTgft\ndhterxcej8eQoMvlgsvlMp89DSLjOev1Omq1Gu7du4fvfve72NnZMeTpdrvR7XZRr9dRr9fRarXQ\narVMW91uN3w+H5aXl7GysoJ8Po9cLmfeoyeutYbf70coFMLOzg68Xi+azSa8Xi9yuRwqlX7lFz3y\nQCAwED04RO7AwXgw9SQuMUyOeNLzFYtF5PN5JJNJJJNJNBoNVCoV+P1+hMNheDynY0LbA7916xZu\n376NQqGAbrcLv98Pl8tljg2FQoZ4+dPr9TA/P4/FxUXcuHEDN27cwOuvv467d++i1+vB7/dDa41A\nIACPx4NgMAifzwe32w2ttfHkM5kMarUaqtUq8vk8rl69iqtXr55Kux04cPBoODckfhJeIT1vyhTt\ndhvZbBbr6+uo1+vodrsol8soFApIJBLwer1wu90n5oWyDSRnrTV6vR42Njbw1ltvIZPJoFqtwu12\nm59erwelFLxeL3w+H3w+n9G+O50OUqkULly4gOvXr+PFF1/ErVu3UK1W0el0jPdN/TwYDJpz8jp6\nvZ7x3huNBsrlMiKRyFASd7zyk8dJ2dR2cE4igj3qc9OMUQ4hx6iMyN1u98CYHYbDbPI4n5E4NyQ+\nCo/SodrtNnK5HAqFAsrlMsrlMra3t7G9vY333nsPWms0m000Gg28+OKLiEQi8Pv9cLsfd4O+4aBU\n0mg0UK/XkcvlsLOzg3q9bmQddiTZAaiDU/ZpNBpot9soFotYX19HIBDAzs4OlFKGtAOBAHw+Hzwe\nj+mItJtSCi6XC8Fg0LR9Z2cH1WrVTB72QD8PA3gScZK5h1GkYd/Dp7Vy7bB2d7tddDodlEol5PN5\nhMNhzMzMIBAIjDzPaY+JqSLxo4xiexg8jp410E/m2bMpCaler2NjYwNra2vY3d3F7u6uqdrI5XLY\n3d01gykYDOLll19GOp0+sQHG65JaeC6XG/juaDRqJBy2SRKu1+uF1hrtdhtaa3S7XZRKJayvr6Pd\nbmN3d9dUqsiKE9pOfj/Py+9rNpvY3d01njyjAftzDk4HtPMwkuH9f9Lzy/M9Ds5jH5DFBnTiGKGn\n02lEIhEzRmzHhhHtcaMf+3uPY8+pIXFpgGGNO6zULZfLIZPJwOPxIBaLodPpoFAoYHt7G2trayiX\ny/D7/eh0OtjY2EA2mzWfJeFduXIFL730EqLRKMLhMK5du4ZUKjWQ3HxSsAPwfMViEQ8fPkQ+nzde\nd6fTAYCBjjHs+71eL0Kh/l7y1WoVmUwGpVIJ9Xod6XR6gJw7nY6Z3OT3A/u2lp5/Pp/H6uqqyRPw\nuGG2d3By6HQ6qFQqaDabAw4KAMRiMUQih+2eejROIkl/XiZzuz+zcGB9fR2rq6sol8uoVqtoNBrw\n+XyIRqNwuVwIBAKIRqPGM+d4svlL/m2PuWHffximhsRH4ThaUy6Xw4cffohAIIClpSU0Gg2srq7i\ngw8+wHe+8x1sbm4iGo1CKYXt7W2USiWkUimkUiksLCxgfn4eV65cwYsvvoilpSXMzc0Z3fmkCZzo\n9XooFAp48OABcrmc8bo7nc7AsYwi5OeokXu9XrRaLVSrVZTLZXS7XQSDQaRSKXS7XVPFIqMRTg7D\nyh05iRQKBayursLlciEejz+xB+jgeGi32yiVSiiVSuY+tVotAP1Ko3A4/ETnP2255iy++yQh21Gv\n15HP5/HRRx/hz//8z9HtduHxeNBqtYxz6Ha7kUgk4PP5EAgEhrZJRlKHRT6PYsOpJ/FhYEkeDba5\nuYmHDx8CALLZrJEFKpUKFhYWsLCwgNnZWcRiMQD7CcVut2uMy0qUVqtlFsUEAoET18MlarWakS9I\n4u1225AtvWcJScCc5elxy4oT+bf9WSZrmeSVNgH6nn02m8XMzIz5DofITwedTge1Wg07OzvIZDJ4\n+PAhCoUCIpEIgsGg6aPZbBbxeBx+vx8+n8/cO/6mdMbXKL3xvvF14GBEyHvfbrfR6/WMjEaMuv9S\n/pGRHMt2I5EI5ufnEQqFEI1Gz8Caxwevl3IhHar79+/j3r17RlLtdrvQWpu8USgUwurqKmZmZjA/\nP49kMmnyWMBBxYC2abfb5jXb/kfh3JG41tqQX6/XQ6/Xw9bWFlZXV1Gv1+H3+9HtdlGr1eDz+QyJ\nX7hwAcvLy5ibm0MkEkEmk8H29rb5HQqF4PF4TKJQa22qU04L9XrdTDYcACRZes7DFgcppUzbAZjs\nOTukzA8opQwRcDCyTfTS+RleQ61WQzabxcWLFx0Z5ZRB7/vevXv48MMPcefOHeTzeczOziKRSADA\nwKraaDSKaDRqtNtWq4Vms4l4PI5kMol2u41arWbkNt7rTqeDRqNhJncpE5JkuA6ByXASEBPqNmTO\niT+dTgfNZhO1Ws0sHJudnZ1IEpc/lDbv37+P+/fvw+PxIBqNGvt6vV6TJwqFQlhcXMRLL71kPHJZ\nimwTOSc1/s/ihKeGxEkw1Aur1SparZbxNjweD1KpFK5du4atrS3s7OwYTTGZTOLmzZu4ePEiIpEI\n4vE4YrEYwuGw8Uo4IVQqFaytrRniXlxcRDgchs/3uE+TOhr1eh2FQgH1et28xrbaiRR6R7J2XHYC\neu625y01OZK4nTyTgxGAkWgoxzgEfnq4e/cu8vk81tbWUKvVsLS0hKWlJQB977lYLKJarZpE9YUL\nF5BMJlGtVk0CutfroVgsmn5ED7NarQ6U1Xa7XbM4DAAajYbpazIvUq/XTcKOHr3X6zX9p1KpoFwu\nm4VnnGD8fj/8fj9arRbq9brZRsLj8WBxcXFsNh4GKS1qrVEul7GxsYHt7W3kcjn4fL4BR4o5Cdp1\nbW0NWmtsbW0hmUwikUggGAyairBgMGjuESUyauuxWAyxWAw+n29g64xROBck3u12Tfnb9va2CR09\nHg98Ph/m5+dN6JjJZNBqtUxp0M2bN3Ht2jU0m03jXbtcLqMvZjIZKKVQLBZRKBSM1+H1ek+142mt\n0Wg0UCgU0Gw2AcB42DL0ZWmgXEFqa+S25CE9ccJ+X1a+2OWMrVYLtVrNeA8OTg8fffQRSqUSNjY2\noLXGjRs3MDMzg83NTWxsbKBer5ukfTAYxNzcHAKBAIrFIhqNhukP1WoVu7u7hhgYgZFQ6VH7fD6E\nQiF0u13kcjk0m01DOpQPmdDjOCA505HIZDJYX19HrVZDvV5HIpHA7OwsUqmUmSA6nQ7q9TqKxeJE\nOgFybJDE6QQWi8WBSKTX68Hr9WJmZgZutxuVSgX5fB7b29sIBoNYWFjA3Nwc0uk00um0ybdlMhlk\nMhlsbW0hk8kgHo9jYWEBi4uLhoPONYlLT7Hb7aLdbpuwhDXSDCm3trawvr6ORqOBdDqNy5cvY3Z2\nFpcvX8bCwoLRu3u9nqnBltqh3+83oenu7i5KpZLxxj0ej5kwTrJdtkwhE5hcZs8BJLVxOwyU5yUR\n83VJ1PZ3SxswsmGlDkN8ht8OTg+cmDl5k3RLpZKZ4GWOhFJXr9dDMpk09zCfz2N9fR3hcNiUxbJP\nt1othEIhxGIxhEIhc55Wq2WqYer1OsLhMLxeLwqFAmq1mpFuGPFSkimXy6Z/cFwC/f7WarVQLpdN\nBZjW+lSj2UeB3Zd7vR4qlQoKhQI2NjawubmJcrls3mNEKrV+v99vynt532q1mllpzfvDibZYLJp7\nWCqVjJqgtUYikTB5usMwVSQuk3WSeEje1POY2Nza2sLm5iZu3bqFd999F88++yw+97nP4cUXX8TF\nixcxMzODcDhsiBrY93bpbWrdX5ZOLW9nZwcff/wxfD4frl69arTyk1x+L5OqrDBhVYrb7R7Yz4Xh\nLL1nSfpSOpF/0262Ns72y/fZbknirVbLLERySPx0EY1GzUZkzWYThUIBjUYDm5ubyGazAxp1IBAw\nofzc3BwWFhZQq9WMR/zgwQOkUimTFyqVSoZgQ6EQUqkUIpHIwLYNJHD2O4/Hg93dXaOrc+VyMBhE\nsVhEpVJBrVZDo9EwfZgePgATXW5ubhpp8klLI08LvV4PuVwODx48wNraGjY3N1Gr1Uz0y6Rzs9lE\npVJBJpNBJBJBKpVCIpFAKBQy/MIJLZ/PGx2d4zyRSCCVSmF3dxcPHjxAoVCAz+dDo9HAtWvXjrzO\nqSJxYHgCzc7mlkolZDIZNJtNBINBrKyswOv14tlnn8Xzzz+PK1euYH5+fqAkSyZm6NnX63Xj2fv9\nfni9XlMbHQgE0G63jcevlDpW6HMc8Lz8brvEj9fW6/UQiUQOLC6QYZ4trRByQuz1egPho8vlMlvd\nVqtVM0HyOuT1TRqJP+71SG3/qHKvo8pahyV7H1cyYH0yPdytrS14vV7UarWBPAejM0ZJ4XAYgUAA\nzWYT7XbbECrvq3QUfD6fkUv8fr+RB9jneV5+H+UU+flQKIRcLod8Po9ms2nknUAggFAoZEpTm80m\nstksdnZ2TKnruOSUo/pKu93Gw4cP8Z3vfMfkJki+cnxJGZPvc4wEg0ETqVB2kg4XdxKlYnDv3j3j\nLB3HCwemkMSBg4OD2Vx2aJYDLS0t4ZlnnsGnPvUpxGIxQ8DHSUiSKEnSkUjEEKbf78f8/LypVqGs\ncBIkrrU2YZokcmDfu6ZMxFJATkA8ziZxWcUibWfLLQBMdQqrGIrForEvk1/tdtt459OEYZGcfB04\nfEfLw96Xx8nJ80kJand31+z3nsvlTAIsHA4jGo2a/iLJWmuNpaUlKKXMfVRKIR6Pw+fzodVqmX7j\n9/sRiUTMSmASC6tXwuGwOT8To7z37G8k8U6nY9Y0BINBJBIJJJNJo3/n83mjKVcqFVPtMqm5lXa7\njbt37+LrX/86Njc3UalUjH1lf+DkRhWAE5bf7zc29Xq9Rg+XXOJyuUwuL5vNIpvN4sKFC0in07h0\n6dKxrnOqSHyYZ0MJhR07lUphfn4ejUYDKysruHz5Mubm5jAzMwOfzzeyAN/+n3IKdXGWb3FRBTeL\nkkk+lnw9CWSJZKVSGajV5gzPH3ox9uY7th5+WFttSM+CGixLE9mBgUFvnZ7DJCaobDxKNY3UnvP5\nPNxuNy5duoS5ublTvsp9yKiwUqkY4pVOCyd2yn9KKSMp5nI5kw8Kh8PQWpuSOJ6n2WyiVCqZrYhJ\n/pwYWPnSbDbNA0nodZbLZbOKmU4Pr4H9lHYsFosol8uG6Hjt7N+TBmri2WzWjMVhFVzSM+eYkRtj\nUVKiNMlcAp2Jzc1Nc48Y9YfD4fPtiUvQQEoppNNpRKNRpNNp3Lhxw3gS9LpZQnXUIOagYIJBlkdx\nxaMcPJxIVlZWnrg9vV4P5XIZmUwG5XJ5wONhkoqvyaoT+f+jhvHDPiOrXfh9/M1QmboqK3ZOs2b+\nJDBqAhu1sKJYLOL27dv44IMP8M477yAYDOLHf/zHDyVxOQmeBILB4EDEx0UlTDwyUqOnzHI+eoMb\nGxv46KOPjMfN83g8HoRCITQaDezs7Jh9gphMo+xRqVSMvru9vY1Go2E8deadSGrlctlcC733crls\nJgQ+tIRbIMuN3CYR9KADgYBZsENylrXvksAZ4ZDk5WKq3d1dlMtlU5JJsPItGo0eqOI5DqaGxEcN\nCqmHs2PaHjHJj9rvcUJiejYABrZ+JaHX63VTCytv1pNCa202vqrVagPkLIl0GFkclzhGEfaw4+hR\nMQpgW5XqL/nO5XID29iOG3alzbD37L+Z+CMpyn0ybt++jffffx/vvPMOIpEIbty4gYWFBaRSKcTj\n8ZHXwVppRnBy0D4KZPmo1+tFJBJBIBAYSLzLBCI1aDoDTIrKbRhYehgMBo00wv4liYlaLp0k7qWf\nSCTMdQSDQQAw56SswqoU9mEuhJFJ2EgkYnbQHAeO6+BIh0Z62DJfBRysLLMXTHEik8cAMMlnThaP\nGtVODYkfB7bmacsLfO2okFprbbREepnDyu8kqZ1kG+RiGgADJCu9YenJHKZ1H5a0s+vLZSmiJGup\nXfL8XH7PjPykY5QNdnd38fDhQ7MN8ebmJtbW1pDL5Uy5HJN1b731FrTW+PSnPz2UxP//9q6tqa3z\nii4JELrf7wJxqSG+TSbjuG7ah04f27f2p/Y5M5081Jk2iRMncZrYIAwCISEkkNAFxEXqA7M2W58l\nW8JQQ3P2DGMjdDk65zvr23vttffm+SsUCnj58iWSySTu3bt3aRDnOXe73YhEIkgmk3C5XCiVSjJX\ntdvtCngTWJmA5MxVFpToXE+73RbuOhKJIJ1Oi0b86OgImUxGJIbsKV+v10XnnEqlEIvFxEnS50NX\ni3I9ORwOeL1eORfxeByBQOC9e75cp/E+Z7GbbhSnWz8TfCkpZCJYG9eGppC0E3p6eopWqyWzC0a1\n/ysQH2TDdkUN8oNMK0B48bj4GOpclzKDYSipGh4/AR5AX9JkkJm8uP7/u15jJvEYgutEZq/XQ6vV\nQqVSQTQa/eC85ijXgmBDj4ic7cuXL/Hzzz+jUqmgVquhUChgfX0dh4eHfX3Wj46O8PPPP+Pk5ATz\n8/N4+PDhG59BLnpzcxM//fQTjo+P32sKElUgTJrTq7fb7X2JTEaI/NvR0RGq1apUeG5tbaHZbIqD\nwMhyenoa0WgU0WhUkm3MBfl8PrhcLlSr1T5pnMPhkOZwyWQSu7u7KJfLsj6Yo9L9W7rdLtxut/C9\nTqcT4XBY6KIPYW9bM9pRM5P4BF1iAjdOl8v1BuBrx1ELDfQ9yAjKbrcLA8B1xE6kb7P/KxA3PS3+\ny/BnVNDlBex0OiiVSiiVSshms2g0GlKir6fHD+sdcRkjncJye04PASDHNDExIYt/UFKT/w5K2A4C\ncC4qeviDvPJB5+7o6KiP9rnJdnZ2JiXO29vb2N7eFu8yl8thZWVFQn4m87R3RYql1WrB4XBI0Ydp\n9OpzuRy2trYQi8XeS8VD7pugS4UEqTzgov8GcH5N+BgVKWyWxQZutVoNqVQKy8vLiMfjokXf3NzE\nwcGBtGaemZlBIBAQkC0UCmg2m/B6vaIPPz4+RqlUwsrKigCP3W4XEOePVtBQG+5yuaQm40Obdlx4\n/+v2ALp//qAeRMQDXSDHQjxNgxLc9fnRogluopVKBaVSaSQH4MaC+DjaXP1383kmzTCMehgkOzs7\nO8P+/j42NjYEyHw+H7LZbJ9nf5XFPgTxer0uHhE5Mi54zsHUnvggz1uDNr+7uZnpczJIOqUf1xsE\ngY3Ve9cRlYzynu+ixeh5N5tN6QSYy+WwtrYmU5s2NzextbWF6elp+P3+vv4WrAdgNEJOmePteC74\nnI2NDTx//hzFYhGdTkfAgOA1LvVGoGByk0lD9j/hJksOmp/B42For9sNs2XqwsKCVHWyVJ4jANkw\ni4UrNpsN0WgU7XZbKpwJyru7uyiVSnIMbrdbKj/N78LzRseH1+dDmnnvcG3X63WpojS5cX1PDMIN\n7Y1rCoWP8T48PT2F1+vtq6Ll5KBqtXq7Qfy6zJQHDfJOmZVmkjSRSAAAyuWyhKInJydoNBp9XvFV\nGCmTZrMpF5Q7NC+69paBwdWYJvCapjc984evYYEC5YRmPoCeKXnP67JBmxFvqmFGwNjb28OrV6+w\nurqK9fV1GQJC5c/Z2Zn012F4rFv0ulwuTE1NodVqwefzIR6P46OPPkI8HpdrxQrKUqmEp0+f4ssv\nv8Ti4iKePHmChYUFKbv2+/1j1xIkk0mR5VGdQprD5/OJdpyeeDabxezsrFTUHh8f49mzZ+JhR6NR\npFIpZDIZRCIRtNtt5PN5FItFWd/0JKvVqvRjCQQCuHPnjlAu6+vrAkydTkdGlDmdTpFlttttNBoN\nTE5OIhAIiHyRiXu/349WqyXJ0Q9p2nk5OTlBsVjEq1evUCwWpcGYw+F4gzbkOqM8kPeCThQD6Gs+\npyuhDw8PkU6nsbCwgNPTU9TrdWllMOo99asCcQ3WZvWipg9Yseb1ehGLxdDr9fr6QdAjpvpAl+2/\nrzGLrUFcc/DczTVFNAiodbj3tvOgHzPliiyXNpULump0amqqj7u/KjPpIfN7DUoa8dwQWMhNP3v2\nDN988w1WVlaQz+eFJqEElZ0utVyM546gTu4zm81icXERDocDe3t7Em6vrKxgdXUV33//PX788Ucs\nLCzgk08+QTAYlGpLcsLjWCwWg81mk/F61GR7PB54vV4cHx8LiPd6PYTDYdy9e1e8yK2tLaysrEii\nem5uDnfu3BE57sHBAUqlEra3t/toA1I29XodkUgEgUAA2WwWHo9HpttwA4/H44jH44jFYojH41hd\nXUWtVhMFDcvKWTDGpD1B/CaU3et1dnp6KrRYtVqVIidSa1o8wUiLa06rx7gmTR6ca4ubpdPpRCwW\nAwA4nU4Eg8GxZvf+qkBc2yAg48JlgytO9QGAYrGIYrEIj8eDYrGIw8NDdDodeDyeK29qzwo3Svt4\n0bkQSKWQEx9Eo7wL2PWi0ouL4N3r9foqYfXr6UXwb1cN4oOA2/z+5vVrtVpSEVgulwWYtre3USqV\nsLu7i16vJ53mtEyMN6LeyBjqV6vVvpuQ/TPW1tbg9/sldGay9KOPPsKTJ09w79496Z7JsvbL5E3I\nne7s7GBzcxP1eh3RaBTxeBzBYFDaIrCPTSgUgs/nQ6lUkqlQ7O/ByuN0Oo1gMIiJiQmEw2HcuXMH\nTqcT29vbaLVasNls8Pl8iEajCAaDUg9Ap4L8Nr1SUk1OpxPxeFwSc6QHotEo5ufn0Wq1UCwWhbcP\nh8MfvFqT94pu4UzOPhKJwOPxyHrTXjjXCe9Vrhmdh9NArikvJp8Z5bZaLayuriIej8sUsZmZGQH2\nd9mNBfFxdJKjmgYHs9UkQ2NdnUc9cCQSER610+lgZ2cHJycnknAap7pqlGPUvUl0lSSPm+Bqgpnm\naAd9b52o1LpXDeJcrARxPf2FgMfvzg3kOjxx/X1opjejk671eh2bm5vI5XJ49eoVfvnlF/znP/+R\n1sRut1ukkFo6qVUqplxM36BUCZRKJeRyOYmUqHmOxWKIxWL47W9/i7/+9a/S7ZFSM+Y1hiWXhxkr\n/crlMjY2NqRrXjQaRSAQkOQ3lVQszDk8PMTm5qbw+KyYjEajUjHJxOfCwoIcL5N2Pp8P4XBYZtLS\ny+SGp2kD0gkOhwOxWEySwOSVo9EostksSqUS8vm8RA6UPL7P2hnnteb5H5QDAiDXOxAI9G2++v4x\nPXFeK64H3ZROt6vQ9CgVRe12G6urq3A6nbh//z7m5uYwMzODSCQy0ve6sSB+XWaCAgDp/FYqlaRJ\nTyqVQjweR6VSkRaU3W4XgUBAsvntdlu6wl2lVpzeri63pwfEqjyCuQnawxa19ji4iEwOXH8+cJF1\n1x6/TtpoEL0OENdgZwJfuVyW9qDkc8vlMmq1GhqNhvSuiEQifQUl7CPCG1BXxJrG7006id99cnIS\noVAIbrcbDx8+xN27d/sism+//RblchmFQgFnZ2eYmprC3NwcHjx4gGg0Opamvlqt4ujoCF6vV7pu\nApC5qW63G9lstq8cfnt7G91uV6hAAOKcJJNJBINBdDod2YzYGZF0DxVR5OK5oTP3w42OCTo+XqvV\nkMvlpLR8fn5euHBqz7VTwmKgYUqfcW1Qch8YXpE7bH01m018/fXX+OKLL7C6uirVmhqY+RreT/p3\n3if6s3WUZxbpMapnvu1XXezzLjN3Xlqr1ZLyarbd5IglFn6wnJncIMe0XcesTS1JMimMw8NDmSCi\nZ2eO+v0BvHGs5jnh7/QgNYjrKTBmxdp12LDFvLOzg++//x7fffcdnj9/LqoKu90u8jU2ZuKxszLu\nXe/Nv1HvzCiN9BYH487MzODPf/4z/vKXv8hrvvrqK3z11Vd49uwZvvvuOwDnk+g/++wzkZGNA+Lk\n3TnEhGBAuWQikZBugPRuuXnEYjEZAsFEYiKRQDAYRL1ex/r6OsrlMqrVKvx+P37zm9/IyDHSU+12\nWyotE4lEX1Whw+GQ/09OTqJeryOXy0njq0AggMXFxb7e54NA/ODgYOTzMczMZL6+13Wx3NvUa7RW\nq4VvvvkGf//73wVU+R3NdW9Gsvpf8z7Tka92ntgczALxEYwnRndVY5Lm9evX0qh+enoaOzs7cDgc\nUvBBb0zzj6ZX+z6mlR8meOuucxz1pGd+6iKCYe8L9A8Y0OeEP9qzpkKHg3e5gMnVm8BPD+V9zsXJ\nyQlarRaazaaoKeil8P1J5WxubmJ9fR2FQkEKUHgt9ObGDUdPQ9ISL32ezBtSJ1C5ofF1rVYLHpak\n2AAAHOlJREFU+XweX3zxBUqlkjy/UCigUChgd3cXU1NTsvFVq1W8evUKjUZjpB7RtEAgILUBzFew\nD4rL5cLe3h6q1ar09un1zof1VioV5PN5+P1+4c6pCmFSkt0Ra7Ua7HZ7n3SR53h/f18m0rTbbZyd\nnUlLARYXEZjj8bhw+N1uV/JLXE9ut1uGa1erVZydnQ1skzGKaYrQXHNmdGkmFmksqmOUwihOJ4N5\nvjXw6kIe7YlrusX8P9DfvoPP19Ql11Qmk8Hs7OzI5+JXBeLARWEET9i//vUv5HI5WcAulws2mw07\nOzs4OjqSmXdA/zQPAsVV0yjaU9FJN95cLHkmiDOMHsSP818udM1t0wZRK1ykrCQzQXzQe+rHLmsn\nJydS9p7P51EoFLC/v496vS4gzMkn9KpJIbCSkUDP88iCCm6O/M6c5MTHTDDgeSC1wESoLphh97nP\nP/9c+G+CKbtq8kbd39/Hy5cvsbOzg7/97W8jn5NQKCQFNFwDTqdTZsGura2hVCrJumBis9ls4tWr\nV0gmk+h2z0vBOXCbGyHBuNFoyBACrqVOp4PNzU2USiX0ej14PB6pWyA4E8S5QTgcDkQiEblWlUoF\nr1+/lgjA7XYLZ14qlXB2diadRy9jZmQ9rgPB0XYbGxtYXV3F69evJRFerVbFiWGzN1NpwnWh6zg0\n7TaIetFRAZ9Lx6PVamF9fR1zc3OS/B3FPiiIm7spcPmEpn4v/ZgGGyYMi8UicrmceN9M1DidTszP\nz2N+fl7oE8q5CBo2m024SHZIvAogZ0JTl/gSSHRP8UH0xSCKyHyuCfDmgteeA5+vAZ039vHxsZQY\nm9GJLkQa13766SccHBxgc3MThUJBwnwCNo+F+md9U5kNvMzHdFEM6RCtTDHPqZkg1hp5TXUBkL4y\nOoehk88aNNkHfhyjiiEUCuHo6EiAheuReQHgXNPOnuGkUcxpMtyEHA6H0DPsasjryGQqZbaM/jjQ\nQE/S0kVQdrtdNi5Wxq6srCAQCEgrXI/Hg3g8jsPDQ0QiEbkvL2smeHPT1E24eN650XJA8+7uruj7\nd3Z2UKlURHd/fHwskRQFDNSJm/e7rjjl+WFylAOV6Tg2m80+SoXHbLfbZXOrVCpjVbF+cE98GE/9\nPu9lerL0NjneKpfL4enTpyiVSuJpskz27t27+P3vfy8gQA+sUqmgUqmILpja4qviw+k10hvS34eL\ngBdee5YakPVG+K5kp+bn9PnStAJvBj6XUrWJiQn4/X75HCZc2af6Mvbs2TPs7+9jZWVFeivrEVa8\nHvzupHv0d9QTiOg16wjFpEg0xaI9b/07z4mmZUgbOZ3ON6go3TBNl2BTxz2uMZFKwOVa4HxGUjdM\nfPIYSFOcnp7P1+R3cTqdAACPx4NQKITp6WnJJeimb2dnZ9KsioN+SSPp3IjNZpPzzmntvM8KhUIf\niM/NzWF+fl5oKX4nnacYx4bhBZ0hTpMnZcTfC4UC1tbWUCwWpW+/Vl5p75jXUAOyjuJY7EVKhOtw\nenpaonjdD/7g4EDWDPMKXJNHR0col8vY29sba2P74CAODJ82M+w5o7yf9sC73fNKqnK5jLW1NeTz\neWmdeXp6CpfLhaWlJczOzmJxcVGkPWbGempqqm8smW7T+b6mPXHSJ5onp8pBg4QO1fgeJh9oRjuD\nIhbzefqHHoXf75cQnAtWgwojiMsAFXBOG7A3CAA0Gg2ZbqQ9XX6ePm69cevoixuQmYziv7xB9WZp\neveDpKiDaCOdODM/x2Y7b/sajUZH1v7SKAckPcONnsChKS+bzYZarSbet9mvg9p3SmhJybEQh7kW\n2sLCAk5OTqQPOYt3WIGp1T3dblc4d0rt9DiyRqPR1wI3HA5LZeJlmqcxr9VoNFAul7G/vy/Hw2iN\nHniz2ZRujCcnJ6I4Y5dKsyWClvDyXxb38Xtpx4rHw8Qt1xuL4Qj03W5Xisd4PbQDSLEEi65GtQ8O\n4m9LSFzmvfgeBKCJiQlpu1koFPDDDz9gf39fONS9vT04HA48evQIn3zyyVt7ROv35k49ypCJUUx7\n4gwDGcZzceppLASdd22AmhIZRDUNMpMz9/l8wkfzu5vFDPp4L2MPHz5Eu91GKpWSYh3enMzc8/P1\n55m8o3keeHNpz8bcHE25JI2bNH/4nXU4zB+zglY7ETyHs7OzYw8OaTabojVngq3b7UoBEYt22JRt\nd3cX6+vrQkXR2+PxE2gJXOwm6PF4EIlERGJ4enqKSCQiyb96vS7R0fT0NOLxeN+wbAIQxyJmMhlE\no1EkEgnZhOmcsJPhoP4qo9rJyYkMFn727Bl++eUX2dz0JkewpT6b3rWZS9LXj/e2w+GQBmIbGxso\nFApyrrhm+J7c4DhfgC0ftBPS6/Xg9/v7mmWRbtNrlbmeUe2DgvhVgd+w9+YPZ25ycVMTSw8znU7j\nzp07yGQybz1WTR/ohNdVfA+gf3gFv5tu5zk9PY1YLCZlyho038brDqJWtJfIxWsCIhcptcnFYrEP\nPDW9M6gwaRzj7FOXy4VQKIRYLCb8ZL1el1CYP7xRdfUgj9+kQQjiOiFlOg/6cc1pM3nHH3pPgzxx\n3XeeORWex4WFBekaOK4N4uPdbrfQEl6vFx6PR8Dp8PBQkr38PtyINGd7fHws9wCHPJAH5udNTExI\nx0QCEd9P10cwz0Cvl3K5cDgs1FMkEpHIiCBFx2Tc89FoNLCysoIffvgBz58/x8rKikSxusiK14RR\ni/aEGVFqhYmmSWw2G4LBIObm5sSJoX5eOwL8HtyYuHGa4yDNNWQep6bzxrEP7olfh5lJu2KxiK+/\n/hrVahXA+Q1Xr9eRSqXw+PFjLC8vj1QdxQXI8mOtznhfM0GUi08DpMfjwczMDCYnJ8VDG5aR1/QA\nPQ6TJjE9WH2T6puYYTc9Dv7oEJ3Rw/tEUpzw7fF4kEwmhaPUiUFKD3WHuWaz2TedR9MnvNG46djt\ndgmJ+Z34u775CC5UmpDKGsaz6/MIQLog8vlMEI4LWORMSQnS8w0Gg3C5XPB6vUJVMF/BQby93oU2\nnsDBgeG6aCcQCMDpdMr51tp4TZNx09C5EZfLJdJGnvNGoyF5jUAggGg0inQ63adwYgETaaJxrNvt\nol6v4/vvv8c///lPGZBhRkFUjgAXdKJ2PvgcXjudtOV393q9WF5elsTm+vo61tfXZWPiWnC73eKl\nsx6Aa5KyXE3Z0LQzRZAft3jwRqhTzMdMqQ5ByOl0vrNboL6RmPzJ5/PI5/Not9viIfn9fmkGND8/\nP/R49HsSVAkW5uddhXGxaaqCC3N6ehrBYBC9Xk+SMbqXuQZ0Llb+TWujtVKDP3pD0olNVuSxqInH\nxW6K3AwInpcFcd4MlGuZ3i6BmF4ewZsyOX2zDOPA+d10oQpBnL+TetBVejzHZrWdPpfmD6VpfD9d\n+TqO6XPc6XRQr9eFGgAuJj2xo6SpUOGUdnrPnGyvry+BnhszuwrynALnwyicTid6vZ68J787B//S\njo6OsL+/L9eCG+fx8TH29/clcqI+fNxzUiqVsLW1hdXVVeRyuT71lmn6cTOC1LptfW11krPRaKBa\nrcLj8eD+/ft9TbDoVeskpebMqUSiA6WjeR0tDnIGdT+ad9mN8sSZ6WaCjyHz4eGhaEzH6XhWKBTw\n4sULbGxsyO7aarWkTejS0tIbiSaTF9U3LLk/hvHDFs5lbFioT9NqGa15JtDoHZ3Hq4FMA7NeQHyN\nXsx8Hr0+TkH3er19je6BiwXK63ZZECdAkK7hjWkmLPlch8OBUCgkSSPT+9Y/NPPYeK7Mf/VzzeQd\nnQr93tzY+HcmIunt0wFhx8SFhYWRz4velDmth84JJ8lQVXJ8fIyZmRmEQiHxxklF8bOpYmFCsVar\nYXV1VTjkqakpGe9G6SGLfSgJPD4+RqVSEd14KBRCOp2G3++H3++X3jXNZlPkoIwU6vW6JMuj0ag8\nPo69ePECr1+/RqlUktmUjCR4/rVHTdPXkE6I2+2WdsOMKilW6PV6WFlZwe7uLh49eoRHjx4hmUzi\n4cOHEk1wbVCH32g0RMVmTgSiDdOQ8zEWvbFL6rvsRoE4wYCeFjXCDMsCgUDfTgoM1kbzQhWLRfz4\n449SPswM/MzMDO7evSseuPn6QSCuj4/h5FWCuP4Mfq4GdlIbmhbRoKW9d+BioZivGfR5Jg/HzyMo\na0rFfJ4G8ffxxLWHo8Gcx8jvphUDJo9obrjm9THf28wbmNGfCdjcXEzVhwZxXVzECJIR0GXkl4wE\ndD6GiS+dHCPn6/V6EY/HBdhI6bDKk/y5BvFarSaVlWy5S7BmwtPj8ciUH/YzpyNDPjgSiSAej2Nn\nZ0fen3JDUnCssSA/f5n1srOzg2q1KhOltIbblOIOkpAS4LletAPD9cXj29vbQ6lUQiqVkg0jnU5L\npaceFELsopyRZnYb1TkBml67upJ0FDXTjQJxAJI9r9fraDQa8mUpr9I75TCjF1+tVrG9vS2L6N69\ne/jDH/6A5eXld1aJmeoDPsaFyK5xV2UECQKEXlC6XJyeOIETQF97SwIJE1HkdfWgY+1508PjIifd\nAJyHxeQ7yZG2Wq0+TpXXYtDCHNeoCmDoP+j8Dkr+6BDYTHBqkDBpJBP0zY1OywzNxJepaNEes056\n8xyRKx0XyJmwpGevHRm94XMKz/z8PGZnZ8UBIuiwKyFHovFcsUCHgAtAgJBgR5ke6YLJyUnEYjE4\nnU6R0dFzJJ9OCSLPkQZUnRhl4dg4xkI7n88nkkiubV1BySiF14rfh7JMl8sFv98v3i7Ph6YogXMQ\nzuVyMtiDFbGcvsU2v1oKq2kSky4Z5Hjo/7Pr5N7e3kjn49pBfJhXO8zobdDjId+k+2G8bffu9c7b\nku7s7GBra0s6ujmdTqRSKTx69AjZbHbo6zVg65ucxhN8HXMlNYgPO28mP296hFyo5O35PuQ9deJE\ne7IMPW02m2TVueCB/kQreVPtIQ467nFNby6DzNzozIQif9dAPQjEdeRiRlp8rW6roLlxDfaDcgqa\n5+SmRO/W4/GMDeL04HhPkALgdeO1dzqdfY2/qOChvNHj8cigAV5Hhvt6ao2WtXJdsFCFtFCv14PL\n5UKv15NcAishbTabFH0RpKkOMjffQddoFGPlJ/M0vB5ae80fLcdlcpHrjIlhJuy1WIE/HMjCKm82\n9+LGRtoEuKA2db7F5Nx5TU1Q12uXxVwUYrzLbpQnbrPZ4PV6kUqlEIlEBFT0In2XF97tdrGysoIv\nv/wSP/30E8rlMpaWlvDpp5/i448/fienPuy9eVMyacOBtVdlOmSnTIx8oaYBzOo/eg9Av6fOv5H2\nIY8aDAaFU6ZXpikB7VEzVOW55zSZQCCASCQiOQuzN8l1GkFVb+YmqA7zrPlcbYN4cJPvNgt/zOdp\nT5yP83e+7jJJTeC8i2G5XJbByzwmghHVK7u7u9jd3RUPjoDSbreFFz84OEA4HEY0GsXp6alQKRzJ\npnMi3CgZ2uuCIs5/5PfkGqF6hm2BdeSnz/fp6Xm3RQ4D7na7ePz48cjnhAomgqQeqacjURPUdXEX\nN1gAfRGc5tQB9GnMnU6n6L+53swEud4kqGzS68eU8/Ica5mszXYui97Z2RnpfNwoEOcOT75N9x/W\nHsQghQq9lXa7jZcvX+If//iHLNBYLIYnT57gzp07fRVppr0rUqCXwTDqKkEc6O8bTgDXKhiGthos\nTU/QBGSCPsM/NrmnpzSIfuANrDl58o70XjjVhpNl3rfYZxTTx/NrsYODA+zv70t/D2rpgQsu12az\noVqtSo8UrvlYLCatXnkPTUycd8Kk8oLDLRh96HNLwGEJu9/vF510rVbr03hPTk5KYyx2BNTUBt+P\nkQiPs1arvVNxZhp7+ns8HtG2k4NnJMrSd+0Z67yH9nwH5UFMh0AX9bABnpadku7icdDx5GN6QzGl\nuZSA6hoRnptR7EaBuLa1tTU8f/4clUoFnU4HoVAI8/PzmJmZQTKZfKOy8uTkBK9fv5Y5h2trawiF\nQlhcXMT8/DySyaRUS13GdOKK4eFVApb2tBk668Rer3fet2JnZ0fC4unpaZGAmZ6iBjsmvTi9nR6V\nWbhDr47JGs7P3N3dlRCPx8icAD2g60z2/prN4XDISDVND2j9t81mE0Dz+/1vKIZIq9ntdhwcHKBc\nLkvSldK/s7OLdgNcK0xkEqDOzs7Qbrdl7fM+aDQaQpsw0cmJQFwPWtpJaimTySAWiyEUCo11ThKJ\nBDqdDhYWFlCr1WQYCEGVihOCN81MXOscCR+jF60VWHoDdDqdfTkrE5iBiz7idCz1Zkvw10VHfA0l\nnfyctzmc2q4dxM2b2vR2h3m/Gxsb+Pzzz5HL5dBoNJDJZPDZZ5/h0aNHUmVG6/XOZ/mtra3h6dOn\nePHiBfL5PKLRKJaWlrCwsIB4PH7pOZgmD31dIK49Zx328e/tdhuVSkWSMWwfymM0w339Wg3i9I40\niPMmIw/KPheUk7GRkKZ7dG8SAv91euK/RqPyI5FISK9uAjg7DrLboC7KAjAQxJvNJnZ3d0X+6HQ6\nxWngcwiELALSYEfJIN//7Oy8vzipOfLkfr9fKEF6tUwk+v1+BAIBpFIphMPht7a6GGSxWAwnJydY\nXFyUql5WqWq9Ns8FPV6gP69iRqHARWJUR7gafHWy0syr6A1Lfw43Xl2zQZqFr6czxHzCOCMfrx3E\n8/k8gH6ds9mPQvNFmhZghRcrwH744QeZ48exW71eD/v7+9je3saLFy/w7bffotVqYXZ2Fh9//DH+\n+Mc/Ynl5eSS95TAzuc9BlVfva9y1qc0NhULClRHUmdDRFV3c4XXGW2vN9WIkZ8fX6iQcQZyLiUm0\nQUDf6XSEE2Ui2gLv6zFypZxSpLnbw8ND+P1+qRbkqEA2aiPlNz09LU4BnRBKEQkapFUA9HnjbFJF\nR4n9WLR3Se+a65QtLUKhkNyfnB6UyWTg8/nESx63NS/N5/Ph7t27Us4/MzMj7YvJzVOZxfXNjUuf\nQ1OzTTNzHcOKvPg7cAHi+t7T+QuCNHsk8XOZW7LZzlslpNNpfPTRR28VYGi7dhDf2NjoA2WGZizX\n5cXU2WSeMCYj2D+Dkrd79+5hcXFRQp5KpYJcLicgHovF+kA8GAxemkbRUi4TxEdR24xqDE/pXTED\nruVLTCzSIwP6p/WYIK75Pq3y0ckVGkNrSvs0iGvZ4+TkJDqdDvb29uS6Mvl6lefDsnMj1TE1NSWq\nFOYgNIhHIhGkUimZk7m1tYVqtSrJN+DCcyZwx+PxvoiSdCE9T3rOdJYajYaoWXivkj4hWPZ6PamK\n1m0Lms2mjLSjpNFut/epO8Yxr9eLe/fuCb2aTqfx73//W3ojtdtt2fQ0N62B2KwF0BEHn2M6Q5pX\nN7lz0+h9k9IxlVX0wlkoFAgEEAqFkMlksLy8PPIEqGsHcYbgukgCuAj/dWJAg/nr168xMTGBRCIh\nCyYWiyGdTuPw8BAvX75Ep9NBs9nE1tYW8vk8Wq0WZmZm8ODBAzx48AD37t2T4QWa8xslgWn+zmMN\nBoPIZrOIxWKX7p09zMyFZe7iOlzj4tA3nS6gIFCTwyb9Ysr3TFkfPRadMNLSKZ2B19HVVW9qlp0b\nVUAaXPx+P2ZnZ6WK1uv14vT0tK+529nZmURt0WgUe3t7qFQqfRWZ5LCpY+caYIWulh1yXQSDQdjt\ndvh8PqHQWObPPA2jM81Rs28MHZKjoyO4XC7E4/GRuV+aBszp6Wkkk0lMTExInxP2/i+VSiiVSjK9\nyCze4v1mArF+fzo2fEzTKvo+4OtMMOd50yoVflYgEBAHc2JiQjbipaUlhMPhkaP9/wmIs3ERGxXp\nKRsEEAKH9u7sdjuSyaQ0lonFYgiHw6JA4VQONlK32+3IZrP49NNP8ac//UkGu2oQN7XBoxrBLBQK\nXQuImwkWetVcKDqjTtAm/whctE3lIuICYOimZ2XSYzK1tXwdIyVNs+j+InrxakrMAvGrt2g0KlQH\nO95NTk5idnZWCtZIxRHECc7UjbtcLmxsbEgi1O12Y2JiQkJ4gjg78LEGQK9J0iYcdnB6eipj2TS1\nQvXK4eGh3M+ke5i8o8IrHA4jlUqN3QBL53wcDgcSiQSi0SiWl5fR6XSQz+exsbGBp0+fSp8XJt4Z\n2fB9TGWWjmJZD6E3GUbCjOzpgNLRMo1grylk3nszMzPIZrOIRCJyLjKZjAzjGNWuHcSXlpYk9OPO\nzRNJz9w8qQz5yB8xk041BkX21WoVBwcHmJycRDqdRjweRyKRwMOHD5FKpeD1evs01JcFcL5+cnIS\ntVoNKysr8Hq9Y41QepdpUORNSUkfgRiAUBdmsYfu5cLzaVZVah0s0F9yz3/p9Wnvgj2OqZclaBPc\n3W63lGIPK9Sx7HIWi8VEF83kHflp5iJIsZD/1p0Sufkmk0mhIHnN3G53nyYcuKDV6DFq+lADHNcF\nazn0Dzlel8sFj8cjEkVSepTVsSZkXBAH+ovytBPicDiQSqWEAuJMTx5Ds9nsq17m99S9zukYsVBK\nCyLYzkDLXTVVO6gOQct0qRzq9XqIRqOIRCISTQUCAaGvxrFrB/GPP/74Db5Jc3C84O12W6rMSJNw\nwoUGEo5a4m4PnEuO0uk0lpeXsby8LCdHe4fvCy68WJVKBc+fP0cgEJDPvwrTOzZBnKXBrJoDIDcv\nFyE9YbNop9friZSJnoIuZNCbmS6SYCKNx9Tr9UROqAtCSOdQLhYIBN6ryb9lgy0Wi6HX6yGZTPaF\n+zp01/83HRVdvGPmUcz1Muj1fEz/O+gY9N91wlwX4fA5xAGu93Hvzbc5Yna7HcFgED6fD6lUCr/7\n3e/k81gIxQjCZrOJdJJdGVnKz/XNnk3m+dTHMIpjaJ5DKsaYozIj4nHs2kH8bbsswYocGUvFKXEj\neFDzSqCnJ87wMhKJIBqNIpPJIJPJSMvaqwzvqdcNh8NIJpPSP+SqzGazyVxEcpbs0+L1epFIJGTH\nZpabXhUvPD0KXSg0MTEh1W3k0BuNRp+uFbiQsjHC0MlM9vzw+XxS3MMELL2tRCIhumLLrs7G9cp+\nDfa2+5rePh0MDcC6ZJ4RBOWEVItQhsv7gzTTTbYPfseRYyXXpj12M9kwSKjP99BN/K/DG6R0a25u\nDp988gnm5+ffS7ZoGhMzDK8ov6rX60gmk3j06BF8Pp8oRg4PD4WzY7UXuUZW77EFKT1ku90uFXxs\nQESaJRQKSQtTnmNSN+x6R4qL70/g5xAHzmq0zLKbaJQYmiIBnTTWRXOMJG66ffDxbDq7e5ONoU4m\nk8Hjx4+RSqXG7r72NqPHG4/Hkc1msby8LPMls9ks7t+/LxNDqDhhOEiqhIOM2cKyWq32cZ+UM7Et\nL7Ps3W4Xfr8fyWQSbrf7Df036ZhEIoFMJoOXL1/i5OQEkUgEiURCht7yWCyz7CbaZemKm26W2zSm\nsVhhnLLYUcxut0si9u7du+h2u6K+WV5extLSUl9JtU5EAf1tAfTgCpNz1PJFvXnSM9fvpxUsAGSD\n8Hq9ODo6QjqdRjqdRiKR6OuRYZlllv3vzALxMY289FUb+W2bzYZIJIJ0Oi3edTgcRigUEhD/EGBJ\nHj4UCmF1dRU+n0+KE5gIskDcMsv+92azyqUts8wyy26v3Xwy2jLLLLPMsqFmgbhllllm2S02C8Qt\ns8wyy26xWSBumWWWWXaLzQJxyyyzzLJbbBaIW2aZZZbdYrNA3DLLLLPsFpsF4pZZZpllt9gsELfM\nMsssu8Vmgbhllllm2S02C8Qts8wyy26xWSBumWWWWXaLzQJxyyyzzLJbbBaIW2aZZZbdYrNA3DLL\nLLPsFpsF4pZZZpllt9gsELfMMsssu8Vmgbhllllm2S02C8Qts8wyy26xWSBumWWWWXaL7b+KYV8B\nDDYncgAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f04addf4850>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 2 - Multi-layer perceptrons"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3) Define a simple Keras multi-layer perceptron (MLP) architecture using Sequential API and containing 3 dense layers: 2 dense layers with 512 units and ReLU activation followed by 1 dense layer for softmax regression. Use your model to get first classification results on Fashion MNIST."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "num_classes = 10\n",
      "z_train = keras.utils.to_categorical(y_train, num_classes)\n",
      "z_test = keras.utils.to_categorical(y_test, num_classes)\n",
      "x_train1=x_train.reshape(A,C*C)\n",
      "x_test1=x_test.reshape(B,C*C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers import Dense, Dropout\n",
      "from keras.optimizers import RMSprop\n",
      "from keras.layers.core import Activation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlp_1 = Sequential()\n",
      "\n",
      "layers = [Dense(units=512, input_dim=C**2), Activation('relu'),\n",
      "          Dense(units=512, input_dim=512), Activation('relu'),\n",
      "          Dense(units=num_classes, input_dim=512), Activation('softmax')]\n",
      "\n",
      "epochs=10\n",
      "batch_size=500\n",
      "\n",
      "for layer in layers :\n",
      "    mlp_1.add(layer)\n",
      "    \n",
      "mlp_1.summary()\n",
      "\n",
      "rmsprop = keras.optimizers.RMSprop(lr=0.001)\n",
      "\n",
      "mlp_1.compile(loss='binary_crossentropy', optimizer=rmsprop,metrics=[\"accuracy\"])\n",
      "hist_mlp_1 = mlp_1.fit(x_train1, z_train, validation_split=0.2, epochs=epochs, verbose=1,batch_size=batch_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "dense_1 (Dense)              (None, 512)               401920    \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, 512)               0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 512)               262656    \n",
        "_________________________________________________________________\n",
        "activation_2 (Activation)    (None, 512)               0         \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 10)                5130      \n",
        "_________________________________________________________________\n",
        "activation_3 (Activation)    (None, 10)                0         \n",
        "=================================================================\n",
        "Total params: 669,706\n",
        "Trainable params: 669,706\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "Train on 48000 samples, validate on 12000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/10\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  500/48000 [..............................] - ETA: 52:14 - loss: 2.7297 - acc: 0.8108"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4500/48000 [=>............................] - ETA: 5:19 - loss: 2.8845 - acc: 0.8180 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/48000 [====>.........................] - ETA: 2:33 - loss: 2.8906 - acc: 0.8186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13500/48000 [=======>......................] - ETA: 1:24 - loss: 2.8944 - acc: 0.8187"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/48000 [==========>...................] - ETA: 52s - loss: 2.8968 - acc: 0.8188 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000/48000 [==============>...............] - ETA: 30s - loss: 2.8913 - acc: 0.8193"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/48000 [==================>...........] - ETA: 19s - loss: 2.8856 - acc: 0.8197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000/48000 [=====================>........] - ETA: 11s - loss: 2.8835 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41000/48000 [========================>.....] - ETA: 5s - loss: 2.8859 - acc: 0.8197 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "46500/48000 [============================>.] - ETA: 1s - loss: 2.8842 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 34s 699us/step - loss: 2.8846 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8662 - acc: 0.8212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/48000 [==>...........................] - ETA: 0s - loss: 2.8678 - acc: 0.8211"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000/48000 [======>.......................] - ETA: 0s - loss: 2.8793 - acc: 0.8204"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000/48000 [==========>...................] - ETA: 0s - loss: 2.8842 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24000/48000 [==============>...............] - ETA: 0s - loss: 2.8872 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 2.8849 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/48000 [=====================>........] - ETA: 0s - loss: 2.8838 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43000/48000 [=========================>....] - ETA: 0s - loss: 2.8869 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 9us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.9303 - acc: 0.8172"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/48000 [===>..........................] - ETA: 0s - loss: 2.8805 - acc: 0.8203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/48000 [======>.......................] - ETA: 0s - loss: 2.8806 - acc: 0.8203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000/48000 [==========>...................] - ETA: 0s - loss: 2.8878 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000/48000 [==============>...............] - ETA: 0s - loss: 2.8843 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32500/48000 [===================>..........] - ETA: 0s - loss: 2.8872 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000/48000 [========================>.....] - ETA: 0s - loss: 2.8866 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 8us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8470 - acc: 0.8224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/48000 [====>.........................] - ETA: 0s - loss: 2.8832 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/48000 [========>.....................] - ETA: 0s - loss: 2.8830 - acc: 0.8202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000/48000 [=============>................] - ETA: 0s - loss: 2.8824 - acc: 0.8202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 2.8845 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/48000 [=====================>........] - ETA: 0s - loss: 2.8832 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43500/48000 [==========================>...] - ETA: 0s - loss: 2.8866 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 9us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8662 - acc: 0.8212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/48000 [==>...........................] - ETA: 0s - loss: 2.8860 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11500/48000 [======>.......................] - ETA: 0s - loss: 2.8896 - acc: 0.8197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000/48000 [=========>....................] - ETA: 0s - loss: 2.8900 - acc: 0.8197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22500/48000 [=============>................] - ETA: 0s - loss: 2.8830 - acc: 0.8202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28500/48000 [================>.............] - ETA: 0s - loss: 2.8876 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "34500/48000 [====================>.........] - ETA: 0s - loss: 2.8881 - acc: 0.8198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000/48000 [========================>.....] - ETA: 0s - loss: 2.8886 - acc: 0.8198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47000/48000 [============================>.] - ETA: 0s - loss: 2.8861 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 10us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8983 - acc: 0.8192"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/48000 [==>...........................] - ETA: 0s - loss: 2.8913 - acc: 0.8196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000/48000 [======>.......................] - ETA: 0s - loss: 2.8841 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17500/48000 [=========>....................] - ETA: 0s - loss: 2.8838 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24000/48000 [==============>...............] - ETA: 0s - loss: 2.8860 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 2.8853 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/48000 [=====================>........] - ETA: 0s - loss: 2.8857 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43500/48000 [==========================>...] - ETA: 0s - loss: 2.8881 - acc: 0.8198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 9us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8726 - acc: 0.8208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/48000 [====>.........................] - ETA: 0s - loss: 2.8787 - acc: 0.8204"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16500/48000 [=========>....................] - ETA: 0s - loss: 2.8726 - acc: 0.8208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/48000 [==============>...............] - ETA: 0s - loss: 2.8788 - acc: 0.8204"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32000/48000 [===================>..........] - ETA: 0s - loss: 2.8826 - acc: 0.8202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39000/48000 [=======================>......] - ETA: 0s - loss: 2.8845 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/48000 [===========================>..] - ETA: 0s - loss: 2.8844 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 8us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8919 - acc: 0.8196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7000/48000 [===>..........................] - ETA: 0s - loss: 2.8864 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000/48000 [=======>......................] - ETA: 0s - loss: 2.8834 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20500/48000 [===========>..................] - ETA: 0s - loss: 2.8862 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26500/48000 [===============>..............] - ETA: 0s - loss: 2.8840 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "31500/48000 [==================>...........] - ETA: 0s - loss: 2.8847 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37000/48000 [======================>.......] - ETA: 0s - loss: 2.8848 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41500/48000 [========================>.....] - ETA: 0s - loss: 2.8854 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47500/48000 [============================>.] - ETA: 0s - loss: 2.8867 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 10us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8919 - acc: 0.8196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7500/48000 [===>..........................] - ETA: 0s - loss: 2.8632 - acc: 0.8214"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000/48000 [========>.....................] - ETA: 0s - loss: 2.8816 - acc: 0.8202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000/48000 [=============>................] - ETA: 0s - loss: 2.8864 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "31000/48000 [==================>...........] - ETA: 0s - loss: 2.8841 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38500/48000 [=======================>......] - ETA: 0s - loss: 2.8858 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "46000/48000 [===========================>..] - ETA: 0s - loss: 2.8865 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 8us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 2.8919 - acc: 0.8196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7000/48000 [===>..........................] - ETA: 0s - loss: 2.8987 - acc: 0.8192"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14500/48000 [========>.....................] - ETA: 0s - loss: 2.8841 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/48000 [============>.................] - ETA: 0s - loss: 2.8868 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28500/48000 [================>.............] - ETA: 0s - loss: 2.8879 - acc: 0.8198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000/48000 [=====================>........] - ETA: 0s - loss: 2.8834 - acc: 0.8201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/48000 [=========================>....] - ETA: 0s - loss: 2.8859 - acc: 0.8200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 8us/step - loss: 2.8864 - acc: 0.8199 - val_loss: 2.8814 - val_acc: 0.8203\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist2=mlp_1.evaluate(x=x_test1,y=z_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   32/10000 [..............................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  896/10000 [=>............................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1824/10000 [====>.........................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2912/10000 [=======>......................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4064/10000 [===========>..................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5312/10000 [==============>...............] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6496/10000 [==================>...........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8000/10000 [=======================>......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9472/10000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000/10000 [==============================] - 0s 43us/step\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 4) Define a generic function evaluate_model() able to:\n",
      "- plot the evolution of accuracy for both training and testing data with respect to the epochs\n",
      "- compute final test loss and accuracy. \n",
      "\n",
      "Use this function to assess the performance of the previously defined model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def evaluate_model(model,hist,x,z,epochs):\n",
      "    #error= [1-x for x in hist.history['acc']]\n",
      "    #val_error = [1-x for x in hist.history['val_acc']]\n",
      "    plt.subplot(2, 2, 1)\n",
      "    plt.plot(hist.history['acc'])\n",
      "    plt.axis([0, epochs, 0,1 ])\n",
      "    plt.title('acc')\n",
      "    plt.subplot(2, 2, 2)\n",
      "    plt.plot(hist.history['val_acc'])\n",
      "    plt.axis([0, epochs, 0,1 ])\n",
      "    plt.title('val_acc')\n",
      "    \"\"\"\n",
      "    plt.subplot(2, 2, 3)\n",
      "    plt.plot(error)\n",
      "    plt.axis([0, epochs, 0,1 ])\n",
      "    plt.title('error')\n",
      "    \n",
      "    \n",
      "    plt.subplot(2, 2, 4)\n",
      "    plt.plot(val_error)\n",
      "    plt.axis([0, epochs, 0,1 ])\n",
      "    plt.title('val_error')\n",
      "    \"\"\"\n",
      "    \n",
      "    print(\"final loss & accuracy = \",model.evaluate(x,z,verbose=0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_model(mlp_1,hist_mlp_1,x_test1,z_test,epochs)\n",
      "print(hist_mlp_1.history['val_acc'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('final loss & accuracy = ', [2.8854428840637207, 0.8200000150680542])\n",
        "[0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737, 0.82025001694758737]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACQCAYAAADz9itwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQVKcY+IKFCKe0REgVLcIyIK9H8PEmbrQjcjCwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f04adc5c350>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Comments: #todo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 5) Define a deeper multi-layer perceptron (MLP) architecture to outperform the previously obtained classification results. \n",
      "Use evaluate_model() to provide the evaluation and comment the performance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlp_2 = Sequential()\n",
      "\n",
      "#layers2 = [Dense(units=512, input_dim=C**2), Activation('relu'),\n",
      "#          Dense(units=num_classes, input_dim=512), Activation('softmax')]\n",
      "\n",
      "layers2 = [Dense(units=32, input_dim=C**2), Activation('relu'),\n",
      "        \n",
      "          Dense(units=num_classes, input_dim=32), Activation('softmax')]\n",
      "\n",
      "epochs2=10\n",
      "batch_size2=500\n",
      "\n",
      "for layer in layers2 :\n",
      "    mlp_2.add(layer)\n",
      "    \n",
      "mlp_2.summary()\n",
      "\n",
      "rmsprop = keras.optimizers.RMSprop(lr=0.0003)\n",
      "\n",
      "mlp_2.compile(loss='binary_crossentropy', optimizer=rmsprop,metrics=[\"accuracy\"])\n",
      "hist_mlp_2 = mlp_2.fit(x_train1, z_train, validation_split=0.2, epochs=epochs2, verbose=1,batch_size=batch_size2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "dense_4 (Dense)              (None, 32)                25120     \n",
        "_________________________________________________________________\n",
        "activation_4 (Activation)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_5 (Dense)              (None, 10)                330       \n",
        "_________________________________________________________________\n",
        "activation_5 (Activation)    (None, 10)                0         \n",
        "=================================================================\n",
        "Total params: 25,450\n",
        "Trainable params: 25,450\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "Train on 48000 samples, validate on 12000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/10\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  500/48000 [..............................] - ETA: 9s - loss: 2.7824 - acc: 0.8208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/48000 [==>...........................] - ETA: 1s - loss: 2.4590 - acc: 0.8345"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000/48000 [======>.......................] - ETA: 0s - loss: 2.3545 - acc: 0.8408"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000/48000 [==========>...................] - ETA: 0s - loss: 2.2592 - acc: 0.8465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23500/48000 [=============>................] - ETA: 0s - loss: 2.1840 - acc: 0.8510"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 2.0886 - acc: 0.8567"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "37500/48000 [======================>.......] - ETA: 0s - loss: 1.9876 - acc: 0.8622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44000/48000 [==========================>...] - ETA: 0s - loss: 1.9192 - acc: 0.8660"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 1s 11us/step - loss: 1.8795 - acc: 0.8678 - val_loss: 1.4882 - val_acc: 0.8837\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 1.4752 - acc: 0.8834"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7500/48000 [===>..........................] - ETA: 0s - loss: 1.3536 - acc: 0.8842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000/48000 [=======>......................] - ETA: 0s - loss: 1.1808 - acc: 0.8869"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/48000 [============>.................] - ETA: 0s - loss: 1.0335 - acc: 0.8913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/48000 [================>.............] - ETA: 0s - loss: 0.9186 - acc: 0.8934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35500/48000 [=====================>........] - ETA: 0s - loss: 0.7978 - acc: 0.8965"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/48000 [=========================>....] - ETA: 0s - loss: 0.7214 - acc: 0.8986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 8us/step - loss: 0.6751 - acc: 0.9000 - val_loss: 0.3037 - val_acc: 0.9128\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.3007 - acc: 0.9124"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/48000 [====>.........................] - ETA: 0s - loss: 0.2965 - acc: 0.9147"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/48000 [==========>...................] - ETA: 0s - loss: 0.2933 - acc: 0.9154"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27000/48000 [===============>..............] - ETA: 0s - loss: 0.2889 - acc: 0.9165"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35500/48000 [=====================>........] - ETA: 0s - loss: 0.2866 - acc: 0.9168"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44000/48000 [==========================>...] - ETA: 0s - loss: 0.2843 - acc: 0.9172"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 7us/step - loss: 0.2826 - acc: 0.9176 - val_loss: 0.2685 - val_acc: 0.9218\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2742 - acc: 0.9210"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/48000 [====>.........................] - ETA: 0s - loss: 0.2685 - acc: 0.9214"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19000/48000 [==========>...................] - ETA: 0s - loss: 0.2657 - acc: 0.9218"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "28500/48000 [================>.............] - ETA: 0s - loss: 0.2638 - acc: 0.9223"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38000/48000 [======================>.......] - ETA: 0s - loss: 0.2644 - acc: 0.9221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47000/48000 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 6us/step - loss: 0.2627 - acc: 0.9225 - val_loss: 0.2578 - val_acc: 0.9248\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2436 - acc: 0.9290"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/48000 [====>.........................] - ETA: 0s - loss: 0.2541 - acc: 0.9247"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/48000 [==========>...................] - ETA: 0s - loss: 0.2524 - acc: 0.9253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27000/48000 [===============>..............] - ETA: 0s - loss: 0.2505 - acc: 0.9257"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000/48000 [=====================>........] - ETA: 0s - loss: 0.2498 - acc: 0.9260"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/48000 [===========================>..] - ETA: 0s - loss: 0.2486 - acc: 0.9264"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 7us/step - loss: 0.2484 - acc: 0.9264 - val_loss: 0.2452 - val_acc: 0.9274\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2531 - acc: 0.9276"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/48000 [====>.........................] - ETA: 0s - loss: 0.2425 - acc: 0.9283"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000/48000 [=========>....................] - ETA: 0s - loss: 0.2406 - acc: 0.9290"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000/48000 [==============>...............] - ETA: 0s - loss: 0.2398 - acc: 0.9288"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "34500/48000 [====================>.........] - ETA: 0s - loss: 0.2391 - acc: 0.9289"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44500/48000 [==========================>...] - ETA: 0s - loss: 0.2381 - acc: 0.9289"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 6us/step - loss: 0.2379 - acc: 0.9290 - val_loss: 0.2343 - val_acc: 0.9299\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2300 - acc: 0.9300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10500/48000 [=====>........................] - ETA: 0s - loss: 0.2322 - acc: 0.9303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000/48000 [===========>..................] - ETA: 0s - loss: 0.2322 - acc: 0.9303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 0.2306 - acc: 0.9305"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40500/48000 [========================>.....] - ETA: 0s - loss: 0.2311 - acc: 0.9303"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 6us/step - loss: 0.2309 - acc: 0.9303 - val_loss: 0.2302 - val_acc: 0.9311\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2346 - acc: 0.9312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/48000 [====>.........................] - ETA: 0s - loss: 0.2278 - acc: 0.9304"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000/48000 [=========>....................] - ETA: 0s - loss: 0.2263 - acc: 0.9309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25500/48000 [==============>...............] - ETA: 0s - loss: 0.2263 - acc: 0.9308"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "34000/48000 [====================>.........] - ETA: 0s - loss: 0.2257 - acc: 0.9309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/48000 [=========================>....] - ETA: 0s - loss: 0.2254 - acc: 0.9311"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 7us/step - loss: 0.2254 - acc: 0.9311 - val_loss: 0.2232 - val_acc: 0.9311\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2185 - acc: 0.9328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10500/48000 [=====>........................] - ETA: 0s - loss: 0.2208 - acc: 0.9325"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20500/48000 [===========>..................] - ETA: 0s - loss: 0.2215 - acc: 0.9320"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/48000 [=================>............] - ETA: 0s - loss: 0.2205 - acc: 0.9321"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40000/48000 [========================>.....] - ETA: 0s - loss: 0.2192 - acc: 0.9324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 6us/step - loss: 0.2175 - acc: 0.9327 - val_loss: 0.2151 - val_acc: 0.9334\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "\n",
        "  500/48000 [..............................] - ETA: 0s - loss: 0.2244 - acc: 0.9312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/48000 [====>.........................] - ETA: 0s - loss: 0.2161 - acc: 0.9328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000/48000 [=========>....................] - ETA: 0s - loss: 0.2114 - acc: 0.9334"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26500/48000 [===============>..............] - ETA: 0s - loss: 0.2102 - acc: 0.9336"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000/48000 [=====================>........] - ETA: 0s - loss: 0.2095 - acc: 0.9339"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45000/48000 [===========================>..] - ETA: 0s - loss: 0.2086 - acc: 0.9339"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48000/48000 [==============================] - 0s 6us/step - loss: 0.2082 - acc: 0.9340 - val_loss: 0.2096 - val_acc: 0.9351\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_model(mlp_2,hist_mlp_2,x_test1,z_test,epochs2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('final loss & accuracy = ', [0.10024541226625443, 0.96869999980926513])\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWcU50JuZVZwDvZlZxTnQm5lV3P8Hr9ked+6rRmQAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f9e7d66c4d0>"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusion: # todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 3 - Convolutional neural networks"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "6) Define a simple Keras convolutional neural network (CNN) architecture using Sequential API and containing the following layers : 1 convolution layer using Conv2D and 32 filters, 1 max-polling layer using MaxPooling2D, 2 dense layers using ReLU and softmax activations respectively. Use this model to get classification results (use evaluate_model() as previously) and compared them to MLP results. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# to do"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from keras.layers import Flatten\n",
      "from keras.layers import Conv2D, MaxPooling2D\n",
      "from keras import backend as K\n",
      "\n",
      "print(x_train.shape)\n",
      "x_train_cnn=x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
      "print(x_train_cnn.shape)\n",
      "x_test_cnn=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(60000, 28, 28)\n",
        "(60000, 28, 28, 1)\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs_cnn=20\n",
      "\n",
      "cnn_1 = Sequential()\n",
      "input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2],x_train_cnn.shape[3])\n",
      "cnn_1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
      "\n",
      "cnn_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "cnn_1.add(Flatten()) #renvoie un vecteur 1,n\u00b2 \u00e0 la place d'une matrice n,n\n",
      "\n",
      "cnn_1.add(Dense(30, activation='relu'))\n",
      "cnn_1.add(Dense(num_classes, activation='softmax'))\n",
      "cnn_1.compile(loss=keras.losses.categorical_crossentropy,\n",
      "              optimizer=keras.optimizers.SGD(lr=0.005),\n",
      "              metrics=['accuracy'])\n",
      "cnn_1.summary()\n",
      " \n",
      "hist_cnn_1 = cnn_1.fit(x_train_cnn, z_train,\n",
      "          batch_size=batch_size,\n",
      "          epochs=epochs_cnn,\n",
      "          verbose=1,\n",
      "          validation_data=(x_test_cnn, z_test))\n",
      "\n",
      "evaluate_model(cnn_1,hist_cnn_1,x_test_cnn,z_test,epochs_cnn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_52 (Conv2D)           (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_32 (MaxPooling (None, 13, 13, 32)        0         \n",
        "_________________________________________________________________\n",
        "flatten_31 (Flatten)         (None, 5408)              0         \n",
        "_________________________________________________________________\n",
        "dense_67 (Dense)             (None, 30)                162270    \n",
        "_________________________________________________________________\n",
        "dense_68 (Dense)             (None, 10)                310       \n",
        "=================================================================\n",
        "Total params: 162,900\n",
        "Trainable params: 162,900\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "Train on 60000 samples, validate on 10000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/20\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  500/60000 [..............................] - ETA: 1:30 - loss: 13.0379 - acc: 0.1360"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3000/60000 [>.............................] - ETA: 15s - loss: 13.1510 - acc: 0.1610 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/60000 [==>...........................] - ETA: 7s - loss: 13.1591 - acc: 0.1720 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9000/60000 [===>..........................] - ETA: 5s - loss: 13.1085 - acc: 0.1790"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000/60000 [=====>........................] - ETA: 3s - loss: 13.1007 - acc: 0.1814"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000/60000 [======>.......................] - ETA: 3s - loss: 13.0288 - acc: 0.1869"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000/60000 [========>.....................] - ETA: 2s - loss: 13.0270 - acc: 0.1878"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21000/60000 [=========>....................] - ETA: 2s - loss: 13.0167 - acc: 0.1890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23500/60000 [==========>...................] - ETA: 1s - loss: 13.0208 - acc: 0.1891"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26500/60000 [============>.................] - ETA: 1s - loss: 13.0005 - acc: 0.1907"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29500/60000 [=============>................] - ETA: 1s - loss: 12.9921 - acc: 0.1915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32500/60000 [===============>..............] - ETA: 1s - loss: 12.9818 - acc: 0.1923"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35500/60000 [================>.............] - ETA: 0s - loss: 12.9775 - acc: 0.1928"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38500/60000 [==================>...........] - ETA: 0s - loss: 12.9643 - acc: 0.1937"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41500/60000 [===================>..........] - ETA: 0s - loss: 12.9604 - acc: 0.1941"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44500/60000 [=====================>........] - ETA: 0s - loss: 12.9574 - acc: 0.1944"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47500/60000 [======================>.......] - ETA: 0s - loss: 12.9389 - acc: 0.1957"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50500/60000 [========================>.....] - ETA: 0s - loss: 12.9352 - acc: 0.1959"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53500/60000 [=========================>....] - ETA: 0s - loss: 12.9230 - acc: 0.1967"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56500/60000 [===========================>..] - ETA: 0s - loss: 12.9178 - acc: 0.1972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59500/60000 [============================>.] - ETA: 0s - loss: 12.9142 - acc: 0.1974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 2s 34us/step - loss: 12.9100 - acc: 0.1977 - val_loss: 12.8961 - val_acc: 0.1999\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 13.2169 - acc: 0.1800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 12.9271 - acc: 0.1977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 12.7990 - acc: 0.2057"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 12.8936 - acc: 0.1999"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 12.9093 - acc: 0.1990"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000/60000 [======>.......................] - ETA: 0s - loss: 12.9025 - acc: 0.1994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18000/60000 [========>.....................] - ETA: 0s - loss: 12.9164 - acc: 0.1986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20500/60000 [=========>....................] - ETA: 0s - loss: 12.9348 - acc: 0.1974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000/60000 [==========>...................] - ETA: 0s - loss: 12.9262 - acc: 0.1980"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26000/60000 [============>.................] - ETA: 0s - loss: 12.9038 - acc: 0.1993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29000/60000 [=============>................] - ETA: 0s - loss: 12.8923 - acc: 0.2001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32000/60000 [===============>..............] - ETA: 0s - loss: 12.8979 - acc: 0.1997"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35000/60000 [================>.............] - ETA: 0s - loss: 12.9036 - acc: 0.1993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38000/60000 [==================>...........] - ETA: 0s - loss: 12.9041 - acc: 0.1993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41000/60000 [===================>..........] - ETA: 0s - loss: 12.8995 - acc: 0.1996"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44000/60000 [=====================>........] - ETA: 0s - loss: 12.9072 - acc: 0.1991"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47000/60000 [======================>.......] - ETA: 0s - loss: 12.9069 - acc: 0.1991"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50000/60000 [========================>.....] - ETA: 0s - loss: 12.9006 - acc: 0.1995"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53000/60000 [=========================>....] - ETA: 0s - loss: 12.8994 - acc: 0.1991"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56000/60000 [===========================>..] - ETA: 0s - loss: 12.8632 - acc: 0.2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59000/60000 [============================>.] - ETA: 0s - loss: 12.8190 - acc: 0.2011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 12.7767 - acc: 0.2025 - val_loss: 7.5876 - val_acc: 0.3080\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 7.2557 - acc: 0.3240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 5.2273 - acc: 0.3280"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 3.5071 - acc: 0.3994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 2.8304 - acc: 0.4407"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 2.4732 - acc: 0.4710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 2.2623 - acc: 0.4886"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 2.1074 - acc: 0.5051"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 1.9876 - acc: 0.5179"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/60000 [===========>..................] - ETA: 0s - loss: 1.8877 - acc: 0.5314"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/60000 [============>.................] - ETA: 0s - loss: 1.8120 - acc: 0.5414"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/60000 [==============>...............] - ETA: 0s - loss: 1.7518 - acc: 0.5480"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33500/60000 [===============>..............] - ETA: 0s - loss: 1.6998 - acc: 0.5547"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/60000 [=================>............] - ETA: 0s - loss: 1.6492 - acc: 0.5628"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39500/60000 [==================>...........] - ETA: 0s - loss: 1.6027 - acc: 0.5705"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/60000 [====================>.........] - ETA: 0s - loss: 1.5584 - acc: 0.5811"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/60000 [=====================>........] - ETA: 0s - loss: 1.5162 - acc: 0.5919"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48500/60000 [=======================>......] - ETA: 0s - loss: 1.4772 - acc: 0.6008"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51500/60000 [========================>.....] - ETA: 0s - loss: 1.4419 - acc: 0.6085"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54500/60000 [==========================>...] - ETA: 0s - loss: 1.4105 - acc: 0.6159"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57500/60000 [===========================>..] - ETA: 0s - loss: 1.3809 - acc: 0.6223"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 1.3546 - acc: 0.6281 - val_loss: 0.7864 - val_acc: 0.7357\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.7510 - acc: 0.7380"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 0.7757 - acc: 0.7311"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 0.7483 - acc: 0.7357"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 0.7307 - acc: 0.7347"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 0.7209 - acc: 0.7398"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 0.7163 - acc: 0.7389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 0.7132 - acc: 0.7382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 0.6994 - acc: 0.7410"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24000/60000 [===========>..................] - ETA: 0s - loss: 0.6948 - acc: 0.7420"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27000/60000 [============>.................] - ETA: 0s - loss: 0.6880 - acc: 0.7423"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30000/60000 [==============>...............] - ETA: 0s - loss: 0.6811 - acc: 0.7435"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33000/60000 [===============>..............] - ETA: 0s - loss: 0.6760 - acc: 0.7450"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36000/60000 [=================>............] - ETA: 0s - loss: 0.6716 - acc: 0.7464"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39000/60000 [==================>...........] - ETA: 0s - loss: 0.6684 - acc: 0.7462"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41500/60000 [===================>..........] - ETA: 0s - loss: 0.6653 - acc: 0.7470"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44500/60000 [=====================>........] - ETA: 0s - loss: 0.6626 - acc: 0.7473"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47500/60000 [======================>.......] - ETA: 0s - loss: 0.6573 - acc: 0.7493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50500/60000 [========================>.....] - ETA: 0s - loss: 0.6536 - acc: 0.7509"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53500/60000 [=========================>....] - ETA: 0s - loss: 0.6507 - acc: 0.7518"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56500/60000 [===========================>..] - ETA: 0s - loss: 0.6474 - acc: 0.7527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59500/60000 [============================>.] - ETA: 0s - loss: 0.6441 - acc: 0.7536"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 0.6442 - acc: 0.7535 - val_loss: 0.5941 - val_acc: 0.7728\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.5512 - acc: 0.7980"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 0.5754 - acc: 0.7803"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 0.5810 - acc: 0.7697"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 0.5694 - acc: 0.7699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 0.5720 - acc: 0.7694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 0.5628 - acc: 0.7745"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 0.5600 - acc: 0.7758"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 0.5589 - acc: 0.7765"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/60000 [===========>..................] - ETA: 0s - loss: 0.5567 - acc: 0.7793"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/60000 [============>.................] - ETA: 0s - loss: 0.5543 - acc: 0.7802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/60000 [==============>...............] - ETA: 0s - loss: 0.5518 - acc: 0.7823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33500/60000 [===============>..............] - ETA: 0s - loss: 0.5512 - acc: 0.7823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/60000 [=================>............] - ETA: 0s - loss: 0.5502 - acc: 0.7835"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39500/60000 [==================>...........] - ETA: 0s - loss: 0.5479 - acc: 0.7839"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/60000 [====================>.........] - ETA: 0s - loss: 0.5463 - acc: 0.7845"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/60000 [=====================>........] - ETA: 0s - loss: 0.5479 - acc: 0.7853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48500/60000 [=======================>......] - ETA: 0s - loss: 0.5494 - acc: 0.7859"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51500/60000 [========================>.....] - ETA: 0s - loss: 0.5472 - acc: 0.7882"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54500/60000 [==========================>...] - ETA: 0s - loss: 0.5465 - acc: 0.7890"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57500/60000 [===========================>..] - ETA: 0s - loss: 0.5444 - acc: 0.7909"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 0.5427 - acc: 0.7918 - val_loss: 0.5230 - val_acc: 0.8146\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.4796 - acc: 0.8340"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3000/60000 [>.............................] - ETA: 1s - loss: 0.4873 - acc: 0.8210"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5500/60000 [=>............................] - ETA: 1s - loss: 0.4813 - acc: 0.8207"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8500/60000 [===>..........................] - ETA: 1s - loss: 0.4858 - acc: 0.8224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11500/60000 [====>.........................] - ETA: 0s - loss: 0.4911 - acc: 0.8195"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14500/60000 [======>.......................] - ETA: 0s - loss: 0.4919 - acc: 0.8197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17500/60000 [=======>......................] - ETA: 0s - loss: 0.4878 - acc: 0.8208"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20500/60000 [=========>....................] - ETA: 0s - loss: 0.4912 - acc: 0.8191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23500/60000 [==========>...................] - ETA: 0s - loss: 0.4903 - acc: 0.8199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26500/60000 [============>.................] - ETA: 0s - loss: 0.4869 - acc: 0.8213"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29500/60000 [=============>................] - ETA: 0s - loss: 0.4838 - acc: 0.8219"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32500/60000 [===============>..............] - ETA: 0s - loss: 0.4864 - acc: 0.8214"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35500/60000 [================>.............] - ETA: 0s - loss: 0.4872 - acc: 0.8216"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38500/60000 [==================>...........] - ETA: 0s - loss: 0.4838 - acc: 0.8229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "41500/60000 [===================>..........] - ETA: 0s - loss: 0.4835 - acc: 0.8229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "44500/60000 [=====================>........] - ETA: 0s - loss: 0.4820 - acc: 0.8240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "47500/60000 [======================>.......] - ETA: 0s - loss: 0.4822 - acc: 0.8241"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "50500/60000 [========================>.....] - ETA: 0s - loss: 0.4798 - acc: 0.8251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "53500/60000 [=========================>....] - ETA: 0s - loss: 0.4786 - acc: 0.8254"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "56500/60000 [===========================>..] - ETA: 0s - loss: 0.4791 - acc: 0.8253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "59500/60000 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8258"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 0.4774 - acc: 0.8261 - val_loss: 0.5097 - val_acc: 0.8106\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.4868 - acc: 0.8160"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3000/60000 [>.............................] - ETA: 1s - loss: 0.4221 - acc: 0.8470"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6000/60000 [==>...........................] - ETA: 1s - loss: 0.4384 - acc: 0.8405"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9000/60000 [===>..........................] - ETA: 1s - loss: 0.4425 - acc: 0.8401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000/60000 [=====>........................] - ETA: 0s - loss: 0.4455 - acc: 0.8377"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14500/60000 [======>.......................] - ETA: 0s - loss: 0.4454 - acc: 0.8372"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000/60000 [=======>......................] - ETA: 0s - loss: 0.4499 - acc: 0.8366"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20000/60000 [=========>....................] - ETA: 0s - loss: 0.4509 - acc: 0.8366"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23000/60000 [==========>...................] - ETA: 0s - loss: 0.4511 - acc: 0.8367"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26000/60000 [============>.................] - ETA: 0s - loss: 0.4480 - acc: 0.8368"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29000/60000 [=============>................] - ETA: 0s - loss: 0.4435 - acc: 0.8382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32000/60000 [===============>..............] - ETA: 0s - loss: 0.4434 - acc: 0.8384"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "35000/60000 [================>.............] - ETA: 0s - loss: 0.4448 - acc: 0.8381"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "38000/60000 [==================>...........] - ETA: 0s - loss: 0.4430 - acc: 0.8391"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "40500/60000 [===================>..........] - ETA: 0s - loss: 0.4441 - acc: 0.8389"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "43500/60000 [====================>.........] - ETA: 0s - loss: 0.4441 - acc: 0.8393"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "46500/60000 [======================>.......] - ETA: 0s - loss: 0.4456 - acc: 0.8390"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "49500/60000 [=======================>......] - ETA: 0s - loss: 0.4436 - acc: 0.8395"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "52500/60000 [=========================>....] - ETA: 0s - loss: 0.4422 - acc: 0.8401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "55500/60000 [==========================>...] - ETA: 0s - loss: 0.4440 - acc: 0.8394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "58500/60000 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8397"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 21us/step - loss: 0.4420 - acc: 0.8403 - val_loss: 0.4573 - val_acc: 0.8351\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.4250 - acc: 0.8580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 0.4255 - acc: 0.8494"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 0.4317 - acc: 0.8448"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 0.4234 - acc: 0.8467"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 0.4198 - acc: 0.8492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 0.4182 - acc: 0.8483"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 0.4180 - acc: 0.8472"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 0.4133 - acc: 0.8489"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/60000 [===========>..................] - ETA: 0s - loss: 0.4118 - acc: 0.8499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/60000 [============>.................] - ETA: 0s - loss: 0.4093 - acc: 0.8503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/60000 [==============>...............] - ETA: 0s - loss: 0.4093 - acc: 0.8500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33500/60000 [===============>..............] - ETA: 0s - loss: 0.4088 - acc: 0.8501"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/60000 [=================>............] - ETA: 0s - loss: 0.4080 - acc: 0.8499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39500/60000 [==================>...........] - ETA: 0s - loss: 0.4084 - acc: 0.8503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/60000 [====================>.........] - ETA: 0s - loss: 0.4089 - acc: 0.8503"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/60000 [=====================>........] - ETA: 0s - loss: 0.4088 - acc: 0.8504"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48500/60000 [=======================>......] - ETA: 0s - loss: 0.4097 - acc: 0.8501"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51500/60000 [========================>.....] - ETA: 0s - loss: 0.4104 - acc: 0.8502"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54500/60000 [==========================>...] - ETA: 0s - loss: 0.4122 - acc: 0.8497"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57500/60000 [===========================>..] - ETA: 0s - loss: 0.4115 - acc: 0.8501"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 0.4103 - acc: 0.8505 - val_loss: 0.4414 - val_acc: 0.8435\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.3895 - acc: 0.8660"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 0.3842 - acc: 0.8600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 0.3968 - acc: 0.8557"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 0.3935 - acc: 0.8583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 0.3925 - acc: 0.8597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 0.3929 - acc: 0.8595"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 0.3954 - acc: 0.8582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 0.3940 - acc: 0.8582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/60000 [===========>..................] - ETA: 0s - loss: 0.3926 - acc: 0.8593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/60000 [============>.................] - ETA: 0s - loss: 0.3926 - acc: 0.8587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/60000 [==============>...............] - ETA: 0s - loss: 0.3956 - acc: 0.8566"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33500/60000 [===============>..............] - ETA: 0s - loss: 0.3942 - acc: 0.8574"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/60000 [=================>............] - ETA: 0s - loss: 0.3929 - acc: 0.8582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39500/60000 [==================>...........] - ETA: 0s - loss: 0.3917 - acc: 0.8586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/60000 [====================>.........] - ETA: 0s - loss: 0.3907 - acc: 0.8592"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/60000 [=====================>........] - ETA: 0s - loss: 0.3880 - acc: 0.8602"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48500/60000 [=======================>......] - ETA: 0s - loss: 0.3889 - acc: 0.8595"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "51500/60000 [========================>.....] - ETA: 0s - loss: 0.3893 - acc: 0.8588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "54000/60000 [==========================>...] - ETA: 0s - loss: 0.3898 - acc: 0.8585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "57000/60000 [===========================>..] - ETA: 0s - loss: 0.3895 - acc: 0.8585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "60000/60000 [==============================] - 1s 20us/step - loss: 0.3906 - acc: 0.8585 - val_loss: 0.4199 - val_acc: 0.8524\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/20\n",
        "\n",
        "  500/60000 [..............................] - ETA: 1s - loss: 0.3528 - acc: 0.8620"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3500/60000 [>.............................] - ETA: 1s - loss: 0.3611 - acc: 0.8657"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6500/60000 [==>...........................] - ETA: 1s - loss: 0.3696 - acc: 0.8660"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9500/60000 [===>..........................] - ETA: 0s - loss: 0.3759 - acc: 0.8644"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12500/60000 [=====>........................] - ETA: 0s - loss: 0.3752 - acc: 0.8651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15500/60000 [======>.......................] - ETA: 0s - loss: 0.3753 - acc: 0.8653"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18500/60000 [========>.....................] - ETA: 0s - loss: 0.3705 - acc: 0.8662"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21500/60000 [=========>....................] - ETA: 0s - loss: 0.3678 - acc: 0.8658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24500/60000 [===========>..................] - ETA: 0s - loss: 0.3686 - acc: 0.8658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "27500/60000 [============>.................] - ETA: 0s - loss: 0.3682 - acc: 0.8661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "30500/60000 [==============>...............] - ETA: 0s - loss: 0.3678 - acc: 0.8664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "33500/60000 [===============>..............] - ETA: 0s - loss: 0.3684 - acc: 0.8662"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "36500/60000 [=================>............] - ETA: 0s - loss: 0.3700 - acc: 0.8657"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "39500/60000 [==================>...........] - ETA: 0s - loss: 0.3687 - acc: 0.8658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "42500/60000 [====================>.........] - ETA: 0s - loss: 0.3687 - acc: 0.8659"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "45500/60000 [=====================>........] - ETA: 0s - loss: 0.3672 - acc: 0.8662"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "48500/60000 [=======================>......] - ETA: 0s - loss: 0.3682 - acc: 0.8662"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-75-04a7c879d709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m           validation_data=(x_test_cnn, z_test))\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist_cnn_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m-> 1092\u001b[0;31m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[0m\u001b[1;32m   1093\u001b[0m             raise ValueError(\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n\u001b[1;32m     34\u001b[0m           self._value != value):\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comments: #todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "7) As for MLP, define a deeper CNN architecture to outperform the previously obtained classification results. What are your conclusions?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs_cnn=10\n",
      "batch_size_2=500\n",
      "\n",
      "cnn_2 = Sequential()\n",
      "input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2],x_train_cnn.shape[3])\n",
      "cnn_2.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
      "cnn_2.add(Conv2D(16,kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
      "cnn_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "cnn_2.add(Flatten()) #renvoie un vecteur 1,n\u00b2 \u00e0 la place d'une matrice n,n\n",
      "\n",
      "cnn_2.add(Dense(40, activation='relu'))\n",
      "cnn_2.add(Dense(num_classes, activation='softmax'))\n",
      "cnn_2.compile(loss=keras.losses.categorical_crossentropy,\n",
      "              optimizer=keras.optimizers.SGD(lr=0.005),\n",
      "              metrics=['accuracy'])\n",
      "cnn_2.summary()\n",
      " \n",
      "hist_cnn_2 = cnn_2.fit(x_train_cnn, z_train,\n",
      "          batch_size=batch_size_2,\n",
      "          epochs=epochs_cnn,\n",
      "          verbose=1,\n",
      "          validation_data=(x_test_cnn, z_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_model(cnn_2,hist_cnn_2,x_test_cnn,z_test,epochs_cnn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('final loss & accuracy = ', [0.34805003582239152, 0.87929999999999997])\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACQCAYAAADz9itwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f023e4a5950>"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comments: #todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 4 - Visualize wrongly predictions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "8) Create a function visualize_wrongly_predictions() able to show wrong prediction for each class for a given model as input. Use this function for each of the 4 previouly trained models (2 MLP, 2 CNN)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def visualize_wrongly_predictions(model,...):\n",
      "    # to do"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize_wrongly_predictions(mlp_1,...)\n",
      "# visualize_wrongly_predictions(mlp_2,...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize_wrongly_predictions(cnn_1,...)\n",
      "# visualize_wrongly_predictions(cnn_2,...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comments: #todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "9) Using the code given below, create a function visualize_confusion_matrix() able to display the confusion matrix  for a given model as input. Use this function for each of the 4 previouly trained models (2 MLP, 2 CNN). What is the most common confusion?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "import itertools\n",
      "\n",
      "def plot_confusion_matrix(cm, classes,\n",
      "                          normalize=False,\n",
      "                          title='Confusion matrix',\n",
      "                          cmap=plt.cm.Blues):\n",
      "    \"\"\"\n",
      "    This function prints and plots the confusion matrix.\n",
      "    Normalization can be applied by setting `normalize=True`.\n",
      "    \"\"\"\n",
      "    if normalize:\n",
      "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "        print(\"Normalized confusion matrix\")\n",
      "    else:\n",
      "        print('Confusion matrix, without normalization')\n",
      "\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
      "    plt.title(title)\n",
      "    plt.colorbar()\n",
      "    tick_marks = np.arange(len(classes))\n",
      "    plt.xticks(tick_marks, classes, rotation=45)\n",
      "    plt.yticks(tick_marks, classes)\n",
      "\n",
      "    fmt = '.2f' if normalize else 'd'\n",
      "    thresh = cm.max() / 2.\n",
      "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
      "        plt.text(j, i, format(cm[i, j], fmt),\n",
      "                 horizontalalignment=\"center\",\n",
      "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def visualize_confusion_matrix(model, ...):\n",
      "    # to do "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize_confusion_matrix(mlp_1, ...)\n",
      "# visualize_confusion_matrix(mlp_2, ...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize_confusion_matrix(cnn_1, ...)\n",
      "# visualize_confusion_matrix(cnn_2, ...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most common confusion: #todo\n",
      "\n",
      "Conclusion:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 5 - Data augmentation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "10) Based on the documentation (https://keras.io/preprocessing/image/), train one of your CNN architecture using data augmentation and conclude on the used of augmented data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "datagen = ImageDataGenerator(\n",
      "    rotation_range=8,\n",
      "    width_shift_range=0.08,\n",
      "    height_shift_range=0.08,\n",
      "    shear_range=0.3, \n",
      "    zoom_range=0.08)\n",
      "\n",
      "# to do"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comments: #todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 6 - Transfer learning from VGG16 trained on ImageNet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transfer learning, is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.\n",
      "\n",
      "In this part, you will do fine tuning on a pre-trained network. Fine-tuning consists in starting from a trained network, then re-training it on a new dataset using very small weight updates. To do so, you need to load a pre-trained model, add a dense classifier to compute the output, and then to freeze the weights of the pre-trained model (https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html).   "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "11) Exploit an architecture already trained on ImageNet (https://keras.io/applications) to improve the classification results on Fashion-MNIST."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras import applications\n",
      "from skimage.transform import resize\n",
      "\n",
      "# to do"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to do"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusion: #todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "12) Challenge: the first 3 teams in terms of overall test accuracy results (whatever the methodology used) will obtain bonus points!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Best accuracy reached: #todo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusions: #todo"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}