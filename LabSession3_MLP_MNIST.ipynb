{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "",
  "signature": "sha256:13e9cbd0888d9cf1749053fd735b4dd73a219040d12a890b53b8913360df0e7e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lab Session 3: Multiple Layer Perceptron"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Objective of this lab session: use a multiple layer perceptron to process MNIST dataset.\n",
      "\n",
      "\n",
      "MNIST is a simple computer vision dataset. It consists of images of handwritten digits. It also includes labels for each image, telling us which digit it is. In this lab session, we're going to train a model to look at images and predict what digits they are."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, start here with these lines of code which will download and read in the data automatically:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import keras\n",
      "from keras.datasets import mnist\n",
      "\n",
      "(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The MNIST data is split into two parts: 60,000 data points of training data, 10,000 points of test data. It's essential in machine learning that we have separate data which we don't learn from so that we can make sure that what we've learned actually generalizes!\n",
      "\n",
      "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. \"x\" corresponds to images and \"y\" to labels. Both the training set and test set contain images and their corresponding labels.\n",
      "\n",
      "First, we will visualize some of the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "plt.figure()\n",
      "for i in range(10):\n",
      "  plt.subplot(2, 5, i + 1)\n",
      "  plt.axis('off')\n",
      "  index = np.where(y_train0 == i)[0][0]\n",
      "  plt.imshow(x_train0[index,:,:], cmap=plt.cm.gray_r, interpolation='nearest')\n",
      "  plt.title('Training: %i' % y_train0[index])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAADeCAYAAADLujArAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjE1ImLiERMnbiISMT+H0otOp9BCohtAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f5067e2c790>"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each image is 28 pixels by 28 pixels. In this lab session, we flatten this array into a vector of 28x28 = 784 numbers.\n",
      "\n",
      "#### 1) Write the code to flatten the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "x_train1=np.reshape(x_train0,(60000,784))\n",
      "x_test1=np.reshape(x_test0,(10000,784))\n",
      "print(x_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 28, 28)\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2) Write the code to normalize pixel intensity between 0 and 1 of images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train = x_train1/255.\n",
      "x_test =  x_test1/255.\n",
      "print(np.nanmax(x_train))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "[[0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]\n",
        " ..., \n",
        " [0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]\n",
        " [0 0 0 ..., 0 0 0]]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each image in MNIST has a corresponding label, a number between 0 and 9 representing the digit drawn in the image.\n",
      "\n",
      "In this lab session, we're going to want our labels as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the $n^{th}$ digit will be represented as a vector which is 1 in the $n^{th}$ dimension. For example, 3 would be $[0,0,0,1,0,0,0,0,0,0]$. \n",
      "\n",
      "#### 3) Convert the labels to one-hot vectors (using the function \"to_categorical\" available in Keras):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_classes = [0,1,2,3,4,5,6,7,8,9]\n",
      "z_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
      "z_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
      "print(z_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Softmax Regression\n",
      "\n",
      "Every image in MNIST is of a handwritten digit between zero and nine. So there are only ten possible things that a given image can be. For a given image, we want to compute the probabilities for it being each digit. In this part, we will use a softmax regression model:\n",
      "\n",
      "$$ y = softmax(Wx+b)$$\n",
      "\n",
      "where $softmax$ is the normalized exponential function."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "4)  Define a Keras network architecture for softmax regression using Sequential API (https://keras.io/models/sequential/). Use a Dense layer to define the softmax regression (https://keras.io/layers/core/#dense)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Activation, Dense\n",
      "from keras.optimizers import SGD, Adam\n",
      "\n",
      "# Build our model\n",
      "model_classif = Sequential()\n",
      " \n",
      "# Declare the layers\n",
      "\n",
      "\"\"\"\n",
      "layers = [Dense(units=10, input_dim=784), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('softmax')]\n",
      "\"\"\"\n",
      "\n",
      "layers = [Dense(units=10, input_dim=784), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('softmax')]\n",
      "# Add the layers to the model\n",
      "for layer in layers:\n",
      "    model_classif.add(layer)\n",
      "    \n",
      "# Configure an optimizer used to minimize the loss function\n",
      "sgd = SGD(lr=0.1, decay=.01) # try this one first\n",
      "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
      "\n",
      "# Compile our model\n",
      "model_classif.compile(loss='binary_crossentropy', optimizer=sgd,metrics=[\"accuracy\"]) # sgd or adam\n",
      " \n",
      "# Fit the model\n",
      "history = model_classif.fit(x_train, z_train, validation_split=0.2, epochs=5, verbose=0)\n",
      "\n",
      "# Model weights\n",
      "model_classif.get_weights()\n",
      "# y = softmax (Wx+b)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model_classif.summary()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "dense_66 (Dense)             (None, 10)                7850      \n",
        "_________________________________________________________________\n",
        "activation_66 (Activation)   (None, 10)                0         \n",
        "_________________________________________________________________\n",
        "dense_67 (Dense)             (None, 10)                110       \n",
        "_________________________________________________________________\n",
        "activation_67 (Activation)   (None, 10)                0         \n",
        "=================================================================\n",
        "Total params: 7,960\n",
        "Trainable params: 7,960\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_classif.evaluate(x=x_test,y=z_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   32/10000 [..............................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1280/10000 [==>...........................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2432/10000 [======>.......................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3552/10000 [=========>....................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4800/10000 [=============>................] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6112/10000 [=================>............] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7488/10000 [=====================>........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8800/10000 [=========================>....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000/10000 [==============================] - 0s 40us/step\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "[0.16104927434921265, 0.93693998088836672]"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "5) How many trainable parameters are there?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have to define the loss function. We try to minimize that error, and the smaller the error margin, the better our model is. In this lab session, \"cross-entropy\" is used as the loss of the model. It's defined as:\n",
      "\n",
      "$$H_{y}(z) = - \\sum_i y_i \\log(z_i)$$\n",
      "\n",
      "where $z$ is our predicted probability distribution, and $y$ is the true distribution (the one-hot vector with the digit labels). \n",
      "\n",
      "Now we need to specify the optimization algorithm that will be used to minimized the loss function. Here, we will use RMSprop. We will also specify a metric (here 'accuracy') to follow the convergence of the training step.\n",
      "\n",
      "#### 6) Specify in the Keras model the loss function, the optimization algorithm and the metric (see https://keras.io/models/sequential/#compile):  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.optimizers import RMSprop\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "7) Write the code to train the model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_size = 128\n",
      "epochs = 20\n",
      "\n",
      "# Build our model\n",
      "model_classif = Sequential()\n",
      " \n",
      "# Declare the layers\n",
      "\n",
      "\"\"\"\n",
      "layers = [Dense(units=10, input_dim=784), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('softmax')]\n",
      "\"\"\"\n",
      "\n",
      "layers = [Dense(units=10, input_dim=784), Activation('relu'),\n",
      "          Dense(units=10, input_dim=10), Activation('softmax')]\n",
      "# Add the layers to the model\n",
      "for layer in layers:\n",
      "    model_classif.add(layer)\n",
      "    \n",
      "# Configure an optimizer used to minimize the loss function\n",
      "rms=RMSprop(lr=0.001)\n",
      "\n",
      "# Compile our model\n",
      "model_classif.compile(loss='binary_crossentropy', optimizer=rms,metrics=[\"accuracy\"]) # sgd or adam\n",
      " \n",
      "# Fit the model\n",
      "history = model_classif.fit(x_train, z_train, validation_split=0.2, epochs=epochs, verbose=0,batch_size=batch_size)\n",
      "\n",
      "# Model weights\n",
      "model_classif.get_weights()\n",
      "# y = softmax (Wx+b)\n",
      "\n",
      "y_pred=model_classif.predict(x_test)\n",
      "\n",
      "\n",
      "model_classif.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "dense_74 (Dense)             (None, 10)                7850      \n",
        "_________________________________________________________________\n",
        "activation_74 (Activation)   (None, 10)                0         \n",
        "_________________________________________________________________\n",
        "dense_75 (Dense)             (None, 10)                110       \n",
        "_________________________________________________________________\n",
        "activation_75 (Activation)   (None, 10)                0         \n",
        "=================================================================\n",
        "Total params: 7,960\n",
        "Trainable params: 7,960\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To study the convergence of the training step, we will plot the evolution of the accuracy for both training and testing data with respect to the epochs. The code to do this is provided below.\n",
      "\n",
      "#### 8) Study the convergence figure and the evaluation score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# list all data in history\n",
      "print(history.history.keys())\n",
      "\n",
      "#Visualize history (loss vs epochs)\n",
      "plt.figure()\n",
      "plt.plot(history.history['acc'])\n",
      "plt.plot(history.history['val_acc'])\n",
      "plt.title('model acc')\n",
      "plt.ylabel('acc')  \n",
      "plt.xlabel('epochs')\n",
      "plt.legend(['train','val'], loc='upper left')\n",
      "plt.show()\n",
      "\n",
      "score = model.evaluate(x_test, z_test, verbose=0)\n",
      "print('Test loss:', score[0])\n",
      "print('Test accuracy:', score[1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['acc', 'loss', 'val_acc', 'val_loss']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMzMLG8OEzMzy5vDxMzM8vb/Acz1fq+xB0d6AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f4e3418e790>"
       ]
      },
      {
       "ename": "RuntimeError",
       "evalue": "The model needs to be compiled before being used.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-96-0eb6ad9fd9b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/campux/virtualenv/deeplearning/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             raise RuntimeError('The model needs to be compiled '\n\u001b[0m\u001b[1;32m    985\u001b[0m                                'before being used.')\n\u001b[1;32m    986\u001b[0m         return self.model.evaluate(x, y,\n",
        "\u001b[0;31mRuntimeError\u001b[0m: The model needs to be compiled before being used."
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Is that good? Compare your results with the score of the current best models: https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "9) Write code to visualize the incorrect predictions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "10) Study the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "import itertools\n",
      "\n",
      "class_names= ['0','1','2','3','4','5','6','7','8','9']\n",
      "\n",
      "def plot_confusion_matrix(cm, classes,\n",
      "                          normalize=False,\n",
      "                          title='Confusion matrix',\n",
      "                          cmap=plt.cm.Blues):\n",
      "    \"\"\"\n",
      "    This function prints and plots the confusion matrix.\n",
      "    Normalization can be applied by setting `normalize=True`.\n",
      "    \"\"\"\n",
      "    if normalize:\n",
      "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
      "        print(\"Normalized confusion matrix\")\n",
      "    else:\n",
      "        print('Confusion matrix, without normalization')\n",
      "\n",
      "    #print(cm)\n",
      "\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
      "    plt.title(title)\n",
      "    plt.colorbar()\n",
      "    tick_marks = np.arange(len(classes))\n",
      "    plt.xticks(tick_marks, classes, rotation=45)\n",
      "    plt.yticks(tick_marks, classes)\n",
      "\n",
      "    fmt = '.2f' if normalize else 'd'\n",
      "    thresh = cm.max() / 2.\n",
      "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
      "        plt.text(j, i, format(cm[i, j], fmt),\n",
      "                 horizontalalignment=\"center\",\n",
      "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "\n",
      "# Compute confusion matrix\n",
      "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
      "np.set_printoptions(precision=2)\n",
      "\n",
      "# Plot normalized confusion matrix\n",
      "plt.figure()\n",
      "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
      "                      title='Normalized confusion matrix')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'y_pred' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-94-bf69abd4fe15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Multiple layer network\n",
      "\n",
      "#### 9) Build a multiple layer dense network to reach 98% of accuracy (at least!)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}